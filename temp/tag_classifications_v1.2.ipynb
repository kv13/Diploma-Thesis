{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "backed-wisconsin",
   "metadata": {},
   "source": [
    "# TAG CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-shanghai",
   "metadata": {},
   "source": [
    "In the second version of tag classifications we will try to predict the tag labels for issues based on descriptions and stack traces. More precise, we will use our word embeddings and stack traces embeddings which have already been created to compute the arithmetic representation of the issue and then based on that we will try to predict the type of issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-bargain",
   "metadata": {},
   "source": [
    "Still, we use logistic regression. Logistic regression used for binary classification but using the method one vs rest we can train one logistic regression model for each label.  Maybe one better version will be using the multinomial logistic regression\n",
    "\n",
    "Moreover, for the arithmetic representation of issues first we will use the average of the word embeddings concatenated with the average of the stack traces embeddings. For those issues missing stack traces we will just zero padding in order to have fixed size. \n",
    "\n",
    "Maybe in later stage we will try to improve the formula using a weighted average based on TF-IDF method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-article",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-sport",
   "metadata": {},
   "source": [
    "First, load the word embeddings and stack traces embedding matrices, the word's and trace's vocabulary and for every issue the corresponding tags and description and stack trace if exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "married-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-opportunity",
   "metadata": {},
   "source": [
    "### Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "happy-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(path_to_file):\n",
    "    temp_dict = dict()\n",
    "    with open(path_to_file) as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            temp   = str(line)\n",
    "            values = temp.split(',')\n",
    "            temp_dict[values[0]] = int(values[1].replace(\"\\n\",\"\"))\n",
    "    \n",
    "    return temp_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "original-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_issues(dir_path,tag_labels,descriptions,stack_traces):\n",
    "    \n",
    "    for fname in os.listdir(dir_path):\n",
    "        with open(os.path.join(dir_path,fname)) as json_file:\n",
    "            \n",
    "            data = json.load(json_file)\n",
    "            for issue in data:\n",
    "                \n",
    "                tags = issue['tags']\n",
    "                for i in range(len(tags)):\n",
    "                    tags[i] = tags[i].strip()\n",
    "                \n",
    "                description = issue['description']\n",
    "                stack_trace = issue['stack_trace']\n",
    "                name        = issue['name']\n",
    "                \n",
    "                if tags != [] and stack_trace !=[] and description != []:\n",
    "                    tag_labels.append(tags)\n",
    "                    descriptions.append(description)\n",
    "                    stack_traces.append(stack_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "subjective-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from stack_trace_embedding notebook\n",
    "\n",
    "def clean_stack_trace(stack_trace):\n",
    "    \n",
    "    clean_stack_trace = []\n",
    "    temp_1            = stack_trace.replace(r'\\tat','  at').replace('\\\"at ',' at ')\n",
    "    temp_stack        = temp_1.split(\" at \")[1:]\n",
    "    \n",
    "    if(temp_stack == []):\n",
    "        temp_stack_2 = temp_1.split(' ')\n",
    "        for t in temp_stack_2:\n",
    "            if t.count('.')>2 and t.find('(') != -1 and t.find(')') != -1:\n",
    "                if t.find('.java:') > t.find('(') and t.find('.java:') < t.find(')'):\n",
    "                    if len(t.split())>1:\n",
    "                        temp_stack.append(t.split()[1])\n",
    "                    else:\n",
    "                        temp_stack.append(t)\n",
    "    \n",
    "    to_find = re.compile(\"[|,|<|>]|\\|=\")\n",
    "    \n",
    "    #find where each function ends and keep only the path\n",
    "    for f in temp_stack:\n",
    "        temp      = f.find(')')\n",
    "        temp_file = f[0:temp]\n",
    "        \n",
    "        # check the punctuations in order to avoid anything else\n",
    "        match_obj = to_find.search(temp_file)\n",
    "        if match_obj == None:\n",
    "            filename = find_filename(temp_file)\n",
    "            if filename != '':\n",
    "                clean_stack_trace.append(filename)\n",
    "                \n",
    "    return clean_stack_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "promising-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from stack_trace_embedding notebook\n",
    "\n",
    "def find_filename(value):\n",
    "    filename = \"\"\n",
    "    words    = value.split(\"(\")\n",
    "    if len(words)>=2:\n",
    "        parts = words[0].split(\".\")\n",
    "        filename = \".\".join(parts[0:-1])\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affected-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from word embeddings notebook\n",
    "\n",
    "def clean_description(description):\n",
    "    \n",
    "    # define stop words\n",
    "    all_stopwords = set(stopwords.words('english'))\n",
    "    \n",
    "    #define translator to translate punctuation to white space\n",
    "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    \n",
    "    #join all lines into one sentence\n",
    "    sentence     = ' '.join(description)\n",
    "    \n",
    "    #translate punctuation\n",
    "    new_sentence = sentence.translate(translator)\n",
    "    \n",
    "    #split the sentense in words\n",
    "    words = new_sentence.split()\n",
    "    \n",
    "    words_sw = [w.lower() for w in words if not w.lower() in all_stopwords and len(w)>1]\n",
    "    \n",
    "    return words_sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "virgin-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from word embeddings notebook\n",
    "\n",
    "def stemming_data(descriptions):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for desc in descriptions:\n",
    "        for counter in range(len(desc)):\n",
    "            if desc[counter].isalpha():\n",
    "                desc[counter] = stemmer.stem(desc[counter])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amateur-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(descriptions,stack_traces,use_stemming):\n",
    "    \n",
    "    clean_descriptions = list()\n",
    "    clean_stack_traces = list()\n",
    "    \n",
    "    for i in range(len(descriptions)):\n",
    "        \n",
    "        temp_desc   = descriptions[i]\n",
    "        temp_trace  = stack_traces[i]\n",
    "        stack_trace = []\n",
    "        clean_desc  = []\n",
    "        \n",
    "        if temp_trace != []:\n",
    "            if len(temp_trace)>1:\n",
    "                stack_trace = clean_stack_trace(' '.join(temp_trace))\n",
    "            else:\n",
    "                stack_trace = clean_stack_trace(temp_trace[0])\n",
    "            \n",
    "        if temp_desc  != []:\n",
    "            clean_desc = clean_description(temp_desc)\n",
    "            \n",
    "        clean_descriptions.append(clean_desc)\n",
    "        clean_stack_traces.append(stack_trace)\n",
    "            \n",
    "    if use_stemming == True:\n",
    "        stemming_data(clean_descriptions)\n",
    "        \n",
    "    return clean_descriptions,clean_stack_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-wilderness",
   "metadata": {},
   "source": [
    "### Compute Arithmetic Representations for Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "possible-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(arithmetic_descriptions,arithmetic_stack_traces,\n",
    "                       word_embedding_matrix,stack_embedding_matrix,use_stacks):\n",
    "    \n",
    "    descriptions_dim  = np.shape(word_embedding_matrix)[1]\n",
    "    if use_stacks == True:\n",
    "        stack_traces_dim  = np.shape(stack_embedding_matrix)[1]\n",
    "    else:\n",
    "        stack_traces_dim  = 0\n",
    "    \n",
    "    num_issues        = len(arithmetic_descriptions)\n",
    "    issues_embeddings = np.zeros((num_issues,descriptions_dim+stack_traces_dim))\n",
    "    \n",
    "    for counter in range(len(arithmetic_descriptions)):\n",
    "        \n",
    "        temp_desc   = arithmetic_descriptions[counter]\n",
    "        temp_stack  = arithmetic_stack_traces[counter]\n",
    "        total_words = 0\n",
    "        total_funcs = 0\n",
    "        \n",
    "        for word in temp_desc:\n",
    "            if word != -2:\n",
    "                total_words += 1\n",
    "                issues_embeddings[counter][0:descriptions_dim] = issues_embeddings[counter][0:descriptions_dim] + word_embedding_matrix[word]\n",
    "        \n",
    "        if total_words != 0 :\n",
    "            issues_embeddings[counter]    /= total_words\n",
    "        \n",
    "        if use_stacks == True:\n",
    "            for func in temp_stack:\n",
    "                if func != -2:\n",
    "                    issues_embeddings[counter][descriptions_dim:] = issues_embeddings[counter][descriptions_dim:] + stack_embedding_matrix[func]\n",
    "                    total_funcs += 1\n",
    "                \n",
    "            if total_funcs != 0:\n",
    "                issues_embeddings[counter][descriptions_dim:] = issues_embeddings[counter][descriptions_dim:] / total_funcs \n",
    "            \n",
    "    return issues_embeddings    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improving-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stemming = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pending-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word embeddings\n",
    "word_embedding_matrix = np.loadtxt('../results_project_3/word_embeddings_g1.txt', dtype=np.float64)\n",
    "\n",
    "# load stack traces embeddings \n",
    "stack_embedding_matrix = np.loadtxt('../results_project_3/stack_embeddings_g.txt', dtype=np.float64)\n",
    "\n",
    "# load vocabularies\n",
    "word2id_path = \"../outputs_project_3/words_vocabulary_g1.txt\"\n",
    "func2id_path = \"../outputs_project_3/stacktraces_vocabulary_g.txt\"\n",
    "\n",
    "word2id = load_dict(word2id_path)\n",
    "func2id = load_dict(func2id_path)\n",
    "\n",
    "#load tags and descriptions\n",
    "dir_path     = '../spring'\n",
    "tag_labels   = list()\n",
    "descriptions = list()\n",
    "stack_traces = list()\n",
    "\n",
    "# load issues\n",
    "load_issues(dir_path,tag_labels,descriptions,stack_traces)\n",
    "\n",
    "# transform data to arithmetic representation\n",
    "clean_descriptions,clean_stack_traces = clean_data(descriptions,stack_traces,use_stemming)\n",
    "\n",
    "clean_descriptions_2 = list()\n",
    "clean_stack_traces_2 = list()\n",
    "clean_tags_2         = list()\n",
    "\n",
    "# remove empty stack traces or dublicate issues\n",
    "for counter in range(len(clean_stack_traces)):\n",
    "    \n",
    "    if clean_stack_traces[counter] != [] :\n",
    "        \n",
    "        flag   = False\n",
    "        flag_2 = False \n",
    "        \n",
    "        # remove empty stack traces \n",
    "        for i in clean_stack_traces[counter]:\n",
    "            func = func2id.get(i,-2)\n",
    "            if func != -2:\n",
    "                flag_2 = True\n",
    "                break\n",
    "        if flag_2 == False:\n",
    "            continue\n",
    "        \n",
    "        # check for dublicates\n",
    "        for counter_2 in range(len(clean_stack_traces_2)):\n",
    "            if clean_descriptions[counter] == clean_descriptions_2[counter_2] and \\\n",
    "               clean_stack_traces[counter] == clean_stack_traces_2[counter_2]:\n",
    "                    flag = True\n",
    "        \n",
    "        if flag == False:\n",
    "            clean_stack_traces_2.append(clean_stack_traces[counter])\n",
    "            clean_descriptions_2.append(clean_descriptions[counter])\n",
    "            clean_tags_2.append(tag_labels[counter])\n",
    "                    \n",
    "del clean_descriptions\n",
    "del clean_stack_traces\n",
    "\n",
    "del descriptions\n",
    "del stack_traces\n",
    "\n",
    "#arithmetic_transformations\n",
    "arithmetic_descriptions = [[word2id.get(word,-2) for word in desc]   for desc in clean_descriptions_2]\n",
    "arithmetic_stack_traces = [[func2id.get(func,-2) for func in trace] for trace in clean_stack_traces_2]\n",
    "\n",
    "del clean_descriptions_2\n",
    "del clean_stack_traces_2\n",
    "\n",
    "issues_embeddings  = compute_embeddings(arithmetic_descriptions,arithmetic_stack_traces,\n",
    "                                        word_embedding_matrix,stack_embedding_matrix,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d099d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1387, 64)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(issues_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-burlington",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2618bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_labels = list()\n",
    "# copy by reference in order to avoid to change every where the variable name\n",
    "tag_labels = clean_tags_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moved-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags = ['Bug','Google Play or Beta feedback','Feedback required','Feature Request','Prio - High','Frontend Design']\n",
    "#tags = ['>test-failure','Team:Distributed','>bug',':Distributed/Snapshot/Restore']\n",
    "tags = ['type: bug','for: stackoverflow','status: invalid','for: external-project']\n",
    "no_tags = 4\n",
    "np_tags = np.zeros((len(arithmetic_descriptions),no_tags))\n",
    "\n",
    "for counter in range(len(tag_labels)):\n",
    "    for counter_2,value in enumerate(tags):\n",
    "        if value in tag_labels[counter]:\n",
    "            np_tags[counter][counter_2] = 1\n",
    "            \n",
    "df_tags = pd.DataFrame(np_tags, columns = tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-fight",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "attractive-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "harmful-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dummy_classifier(tags,df_tags,issues_embeddings,cl_label,n_splits):\n",
    "    \n",
    "    target_label    = df_tags[cl_label]\n",
    "    dummy_clf       = DummyClassifier(strategy = \"uniform\",random_state=0)\n",
    "    total_confusion = np.zeros((2,2))\n",
    "    \n",
    "    # fit model \n",
    "    dummy_clf.fit(issues_embeddings,target_label)\n",
    "    predictions = dummy_clf.predict(issues_embeddings)\n",
    "    total_confusion = confusion_matrix(target_label,predictions)\n",
    "\n",
    "    print(total_confusion)\n",
    "    print(\"accuracy = TP+TN/(TP+TN+FP+FN)\",(total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion))\n",
    "    print(\"custom metric\",np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "                                  (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0]))))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-volunteer",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "organic-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier(tags,df_tags,issues_embeddings,cl_label,n_splits):\n",
    "    \n",
    "    target_label    = df_tags[cl_label]\n",
    "    counter_1       = np.sum(target_label)\n",
    "    weight_0        = 1/(target_label.shape[0]-counter_1)\n",
    "    weight_1        = 1/counter_1\n",
    "    w               = {0:weight_0,1:weight_1}\n",
    "    skf             = StratifiedKFold(n_splits)\n",
    "    model           = LogisticRegression(solver='lbfgs',class_weight = w)\n",
    "    total_confusion = np.zeros((2,2))\n",
    "    counter         = 0\n",
    "    auc             = 0\n",
    "    for train_index, test_index in skf.split(issues_embeddings,target_label):\n",
    "        \n",
    "        X_train,X_test = issues_embeddings[train_index], issues_embeddings[test_index]\n",
    "        y_train,y_test = target_label[train_index], target_label[test_index]\n",
    "        \n",
    "        #fit model \n",
    "        model.fit(X_train,y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        #print(confusion_matrix(y_test,predictions))\n",
    "        total_confusion = total_confusion+confusion_matrix(y_test,predictions)\n",
    "        \n",
    "        fpr,tpr,thresholds = metrics.roc_curve(y_test,model.predict_proba(X_test)[:,1])\n",
    "        \n",
    "        auc     = auc + metrics.auc(fpr,tpr)\n",
    "        counter = counter +1\n",
    "        \n",
    "    print(total_confusion)\n",
    "    print(\"accuracy = TP+TN/(TP+TN+FP+FN)\",(total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion))\n",
    "    print(\"GM\",np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "                                  (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0]))))\n",
    "    print(\"Pre\", total_confusion[0][0]/(total_confusion[0][1]+total_confusion[0][0]))\n",
    "    print(\"AUC\", auc/counter)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project 3\n",
    "my_dummy_classifier(tags,df_tags,issues_embeddings,\"type: bug\",10)\n",
    "my_dummy_classifier(tags,df_tags,issues_embeddings,\"for: stackoverflow\",10)\n",
    "my_dummy_classifier(tags,df_tags,issues_embeddings,\"status: invalid\",10)\n",
    "my_dummy_classifier(tags,df_tags,issues_embeddings,\"for: external-project\",10)\n",
    "\n",
    "# project 2\n",
    "#my_dummy_classifier(tags,df_tags,issues_embeddings,\">test-failure\",10)\n",
    "#my_dummy_classifier(tags,df_tags,issues_embeddings,\">bug\",10)\n",
    "#my_dummy_classifier(tags,df_tags,issues_embeddings,\"Team:Distributed\",10)\n",
    "#my_dummy_classifier(tags,df_tags,issues_embeddings,\":Distributed/Snapshot/Restore\",10)\n",
    "\n",
    "# project 1\n",
    "#my_dummy_classifier(tags,df_tags,issues_embeddings,\"Bug\",10)\n",
    "#my_dummy_classifier(tags,df_tags,issues_embeddings,\"Google Play or Beta feedback\",10)\n",
    "#my_dummy_classifier(tags,df_tags,issues_embeddings,\"Prio - High\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with out descriptions\n",
    "num_issues           = np.shape(issues_embeddings)[0]\n",
    "stack_traces_dim     = np.shape(stack_embedding_matrix)[1]\n",
    "descriptions_dim     = np.shape(word_embedding_matrix)[1]\n",
    "issues_embeddings_st = np.zeros((num_issues,stack_traces_dim))\n",
    "for counter in range(num_issues):\n",
    "    issues_embeddings_st[counter][:] = issues_embeddings[counter][descriptions_dim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facd193",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_issues):\n",
    "    if np.sum(issues_embeddings_st[i]) == 0:\n",
    "        print(i)\n",
    "        print(issues_embeddings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dfbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier(tags,df_tags,issues_embeddings_st,\"type: bug\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings_st,\"for: stackoverflow\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings_st,\"status: invalid\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings_st,\"for: external-project\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "inside-melissa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[485. 648.]\n",
      " [111. 143.]]\n",
      "accuracy = TP+TN/(TP+TN+FP+FN) 0.4527757750540735\n",
      "GM 0.4909158732595112\n",
      "Pre 0.42806707855251547\n",
      "AUC 0.5706586889279018\n",
      "\n",
      "\n",
      "[[577. 610.]\n",
      " [ 84. 116.]]\n",
      "accuracy = TP+TN/(TP+TN+FP+FN) 0.4996395097332372\n",
      "GM 0.5309780202242338\n",
      "Pre 0.4860994102780118\n",
      "AUC 0.586648981626549\n",
      "\n",
      "\n",
      "[[588. 311.]\n",
      " [277. 211.]]\n",
      "accuracy = TP+TN/(TP+TN+FP+FN) 0.5760634462869503\n",
      "GM 0.5317899600820661\n",
      "Pre 0.6540600667408232\n",
      "AUC 0.5636088552149949\n",
      "\n",
      "\n",
      "[[944. 245.]\n",
      " [160.  38.]]\n",
      "accuracy = TP+TN/(TP+TN+FP+FN) 0.7080028839221341\n",
      "GM 0.39035008027904644\n",
      "Pre 0.7939444911690496\n",
      "AUC 0.6046179881408407\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with out stack_traces\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"type: bug\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"for: stackoverflow\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"status: invalid\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"for: external-project\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abefaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions and stack_traces\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"type: bug\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"for: stackoverflow\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"status: invalid\",10)\n",
    "my_classifier(tags,df_tags,issues_embeddings,\"for: external-project\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-slave",
   "metadata": {},
   "source": [
    "## Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset2(issues_embeddings,target_labels):\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    X_train_0 = list()\n",
    "    X_train_1 = list()\n",
    "    \n",
    "    for train_index, test_index in sss.split(issues_embeddings,target_labels):\n",
    "        #X_train,X_test = issues_embeddings[train_index], issues_embeddings[test_index]\n",
    "        #Y_train,Y_test = target_labels[train_index], target_labels[test_index]\n",
    "        \n",
    "        \n",
    "        X_test = issues_embeddings[test_index]\n",
    "        Y_test = target_labels[test_index]\n",
    "        \n",
    "        for index in train_index:\n",
    "            if target_labels.iloc[index] == 0:\n",
    "                X_train_0.append(issues_embeddings[index])\n",
    "            elif target_labels.iloc[index] == 1:\n",
    "                X_train_1.append(issues_embeddings[index])\n",
    "                \n",
    "    return X_train_0,X_train_1,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de459f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(issues_embeddings,target_labels):\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    for train_index, test_index in sss.split(issues_embeddings,target_labels):\n",
    "        \n",
    "        X_train,X_test = issues_embeddings[train_index], issues_embeddings[test_index]\n",
    "        Y_train,Y_test = target_labels[train_index], target_labels[test_index]\n",
    "    \n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(issues_embeddings,target_labels,batch_size):\n",
    "    \n",
    "    batch  = np.ndarray(shape = (batch_size,np.shape(issues_embeddings)[1]), dtype = np.float64)\n",
    "    labels = np.ndarray(shape = (batch_size,2), dtype = np.float64)\n",
    "    \n",
    "    issues_to_use = random.sample([i for i in range(np.shape(issues_embeddings)[0])],batch_size)\n",
    "    \n",
    "    for counter,value in enumerate(issues_to_use):\n",
    "        batch[counter][:]  = issues_embeddings[value][:]\n",
    "        # label_0\n",
    "        labels[counter][0] = 1-target_labels.iloc[value]\n",
    "        # label_1\n",
    "        labels[counter][1] =   target_labels.iloc[value]\n",
    "    return batch,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(issues_embeddings_0, issues_embeddings_1, batch_size):\n",
    "    \n",
    "    batch  = np.ndarray(shape = (batch_size,np.shape(issues_embeddings_0)[1]), dtype = np.float64)\n",
    "    labels = np.ndarray(shape = (batch_size,2), dtype = np.float64)\n",
    "    \n",
    "    issues_to_use_0 = random.sample([i for i in range(np.shape(issues_embeddings_0)[0])],batch_size//2)\n",
    "    issues_to_use_1 = random.sample([i for i in range(np.shape(issues_embeddings_1)[0])],batch_size//2)\n",
    "    \n",
    "    # even indexes for issues belong to class 0\n",
    "    # odd  indexes for issues belong to class 1\n",
    "    counter_0 = 0\n",
    "    counter_1 = 0\n",
    "    \n",
    "    for counter in range(batch_size):\n",
    "        \n",
    "        # even indexes\n",
    "        if counter%2 == 0 :\n",
    "            batch[counter][:]  = issues_embeddings_0[issues_to_use_0[counter_0]][:]\n",
    "            labels[counter][0] = 1\n",
    "            labels[counter][1] = 0\n",
    "            counter_0 += 1\n",
    "        else:\n",
    "            batch[counter][:]  = issues_embeddings_1[issues_to_use_1[counter_1]][:]\n",
    "            labels[counter][0] = 0\n",
    "            labels[counter][1] = 1\n",
    "            counter_1 += 1\n",
    "            \n",
    "    return batch,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_nn(issues_embeddings,target_labels,hidden_layer_dim,learning_rate,\n",
    "                     batch_size,epochs,v_batch,v_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings)[1]])\n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,2])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings)[1],hidden_layer_dim],stddev = 1.0,dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0,dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    # hidden-output layer variables\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,2],stddev = 1.0,dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([2],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    ##neural network's functions\n",
    "    hidden_layer = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer = tf.nn.tanh(hidden_layer)\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer_2 = tf.nn.softmax(output_layer)\n",
    "    \n",
    "    cost_func = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    print(weights)\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # generate batch.\n",
    "            batch_x,batch_y = generate_batch(issues_embeddings,target_labels,batch_size)\n",
    "            \n",
    "            # train the model\n",
    "            _,loss = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "        \n",
    "        # validation\n",
    "        y_preds = sess.run(output_layer_2,feed_dict={X_train:v_batch,Y_train:v_labels})\n",
    "        for i in range(len(y_preds)):\n",
    "            print(y_preds[i],v_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32190808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_nn2(issues_embeddings_0,issues_embeddings_1,hidden_layer_dim,\n",
    "                      learning_rate,batch_size,epochs,v_batch,v_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings_0)[1]])\n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,2])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings_0)[1],hidden_layer_dim],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0/ math.sqrt(hidden_layer_dim),dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    # hidden-output layer variables\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,2],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([2],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    # neural network's functions\n",
    "    hidden_layer   = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer   = tf.nn.tanh(hidden_layer)\n",
    "     \n",
    "    dropout_layer  = tf.nn.dropout(hidden_layer,rate=0.5) \n",
    "    \n",
    "    output_layer   = tf.add(tf.matmul(dropout_layer,W2),b2)\n",
    "    \n",
    "    # for testing drop out is not used \n",
    "    output_layer_all = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer_2   = tf.nn.softmax(output_layer_all)\n",
    "    \n",
    "    cost_func = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # generate batch.\n",
    "            batch_x,batch_y = pooling(issues_embeddings_0,issues_embeddings_1,batch_size)\n",
    "            \n",
    "            # train the model\n",
    "            _,loss = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "        \n",
    "        W1_np = W1.eval()\n",
    "        b1_np = b1.eval()\n",
    "        W2_np = W2.eval()\n",
    "        b2_np = b2.eval()\n",
    "        \n",
    "        \n",
    "        # validation\n",
    "        y_probs     = sess.run(output_layer_2,feed_dict={X_train:v_batch,Y_train:v_labels})\n",
    "    \n",
    "    return compute_metrics(y_probs,v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ee75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_probs,v_labels):\n",
    "    \n",
    "    y_preds_1 = np.ndarray(shape = (np.shape(v_labels)[0],1), dtype = np.float64)\n",
    "    y_true_1  = np.ndarray(shape = (np.shape(v_labels)[0],1), dtype = np.float64)\n",
    "    \n",
    "    for i in range(np.shape(v_labels)[0]):\n",
    "        y_true_1[i]  = v_labels[i][1]\n",
    "        y_preds_1[i] = 0 if y_probs[i][0]>y_probs[i][1] else 1\n",
    "    \n",
    "    total_confusion = confusion_matrix(y_true=y_true_1,y_pred=y_preds_1)\n",
    "    return total_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-amazon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# second implementation\n",
    "# use both word embeddings + stack traces embeddings\n",
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,\n",
    "                                                                      target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the neural network using and stack traces embeddings\n",
    "# metrics matrix\n",
    "start_time = time.time()\n",
    "total_confusion = np.zeros((2,2))\n",
    "\n",
    "for i in range(10):\n",
    "    total_confusion += my_classifier_nn2(train_issues_0,train_issues_1,16,0.01,\n",
    "                                         2*batch_size,100,v_batch,v_labels)\n",
    "\n",
    "    \n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")\n",
    "total_time = time.time() - start_time\n",
    "print(\"training time in seconds %s \"%(str(total_time)))\n",
    "# save neural's network weights\n",
    "#np.savetxt('../results/nn_W1.txt',W1,fmt='%.8f')\n",
    "#np.savetxt('../results/nn_b1.txt',b1,fmt='%.8f')\n",
    "#np.savetxt('../results/nn_W2.txt',W2,fmt='%.8f')\n",
    "#np.savetxt('../results/nn_b2.txt',b2,fmt='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the neural network using only word embeddings\n",
    "descriptions_dim  = np.shape(word_embedding_matrix)[1]\n",
    "train_issues_w0   = np.ndarray(shape = (np.shape(train_issues_0)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "train_issues_w1   = np.ndarray(shape = (np.shape(train_issues_1)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "test_issues_w     = np.ndarray(shape = (np.shape(test_issues)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "\n",
    "for i in range(np.shape(train_issues_0)[0]):\n",
    "    train_issues_w0[i] = train_issues_0[i][0:descriptions_dim]\n",
    "\n",
    "for i in range(np.shape(train_issues_1)[0]):\n",
    "    train_issues_w1[i] = train_issues_1[i][0:descriptions_dim]\n",
    "    \n",
    "for i in range(np.shape(test_issues)[0]):\n",
    "    test_issues_w[i] = test_issues[i][0:descriptions_dim]\n",
    "\n",
    "v_batch_w,v_labels_w = generate_batch(test_issues_w,test_labels,np.shape(test_issues_w)[0])\n",
    "\n",
    "total_confusion = np.zeros((2,2))\n",
    "\n",
    "for i in range(5):\n",
    "    total_confusion += my_classifier_nn2(train_issues_w0,train_issues_w1,\n",
    "                                         16,0.01,2*batch_size,500,v_batch_w,v_labels_w)\n",
    "\n",
    "    \n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_issues_w0))\n",
    "print(len(train_issues_w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59217a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second implementation\n",
    "target_labels = df_tags[\"Google Play or Beta feedback\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,\n",
    "                                                                      target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the neural network using and stack traces embeddings\n",
    "total_confusion = np.zeros((2,2))\n",
    "\n",
    "for i in range(10):\n",
    "    total_confusion += my_classifier_nn2(train_issues_0,train_issues_1,\n",
    "                                         32,0.01,2*batch_size,100,v_batch,v_labels)\n",
    "\n",
    "    \n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd71476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the neural network using only word embeddings\n",
    "descriptions_dim  = np.shape(word_embedding_matrix)[1]\n",
    "train_issues_w0   = np.ndarray(shape = (np.shape(train_issues_0)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "train_issues_w1   = np.ndarray(shape = (np.shape(train_issues_1)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "test_issues_w     = np.ndarray(shape = (np.shape(test_issues)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "\n",
    "for i in range(np.shape(train_issues_0)[0]):\n",
    "    train_issues_w0[i] = train_issues_0[i][0:descriptions_dim]\n",
    "\n",
    "for i in range(np.shape(train_issues_1)[0]):\n",
    "    train_issues_w1[i] = train_issues_1[i][0:descriptions_dim]\n",
    "    \n",
    "for i in range(np.shape(test_issues)[0]):\n",
    "    test_issues_w[i] = test_issues[i][0:descriptions_dim]\n",
    "\n",
    "v_batch_w,v_labels_w = generate_batch(test_issues_w,test_labels,np.shape(test_issues_w)[0])\n",
    "\n",
    "total_confusion = np.zeros((2,2))\n",
    "\n",
    "for i in range(10):\n",
    "    total_confusion += my_classifier_nn2(train_issues_0,train_issues_1,\n",
    "                                         32,0.01,2*batch_size,800,v_batch,v_labels)\n",
    "\n",
    "    \n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14def9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second implementation\n",
    "target_labels = df_tags[\"Prio - High\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,\n",
    "                                                                      target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc351b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the neural network using and stack traces embeddings\n",
    "total_confusion = np.zeros((2,2))\n",
    "\n",
    "for i in range(10):\n",
    "    total_confusion += my_classifier_nn2(train_issues_0,train_issues_1,\n",
    "                                         32,0.01,2*batch_size,2000,v_batch,v_labels)\n",
    "\n",
    "    \n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_confusion = my_classifier_nn2(train_issues_0,train_issues_1,16,0.01,2*batch_size,1000,v_batch,v_labels)\n",
    "\n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c877a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_confusion = my_classifier_nn2(train_issues_0,train_issues_1,32,0.01,2*batch_size,3000,v_batch,v_labels)\n",
    "\n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e27985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the neural network using only word embeddings\n",
    "descriptions_dim  = np.shape(word_embedding_matrix)[1]\n",
    "train_issues_w0   = np.ndarray(shape = (np.shape(train_issues_0)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "train_issues_w1   = np.ndarray(shape = (np.shape(train_issues_1)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "test_issues_w     = np.ndarray(shape = (np.shape(test_issues)[0],descriptions_dim),\n",
    "                               dtype = np.float64)\n",
    "\n",
    "for i in range(np.shape(train_issues_0)[0]):\n",
    "    train_issues_w0[i] = train_issues_0[i][0:descriptions_dim]\n",
    "\n",
    "for i in range(np.shape(train_issues_1)[0]):\n",
    "    train_issues_w1[i] = train_issues_1[i][0:descriptions_dim]\n",
    "    \n",
    "for i in range(np.shape(test_issues)[0]):\n",
    "    test_issues_w[i] = test_issues[i][0:descriptions_dim]\n",
    "\n",
    "v_batch_w,v_labels_w = generate_batch(test_issues_w,test_labels,np.shape(test_issues_w)[0])\n",
    "\n",
    "total_confusion = np.zeros((2,2))\n",
    "\n",
    "for i in range(10):\n",
    "    total_confusion += my_classifier_nn2(train_issues_w0,train_issues_w1,\n",
    "                                         16,0.01,2*batch_size,1000,v_batch_w,v_labels_w)\n",
    "\n",
    "    \n",
    "acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"GM\",gm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee79816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f683db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the neural network using only word embeddings\n",
    "descriptions_dim  = np.shape(word_embedding_matrix)[1]\n",
    "train_issues_w0   = train_issues_0[:][0:descriptions_dim].copy()\n",
    "train_issues_w1   = train_issues_1[:][0:descriptions_dim].copy()\n",
    "test_issues_w     = test_issues[:][0:descriptions_dim].copy()\n",
    "\n",
    "v_batch_w,v_labels_w = generate_batch(test_issues_w,test_labels,np.shape(test_issues_w)[0])\n",
    "my_classifier_nn2(train_issues_w0,train_issues_w1,16,0.01,2*batch_size,v_batch_w,v_labels_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first implementation\n",
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues,train_labels,test_issues,test_labels = split_dataset(issues_embeddings,target_labels)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])\n",
    "my_classifier_nn(train_issues,train_labels,16,0.01,64,1000,v_batch,v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = df_tags[\"Bug\"]\n",
    "print(np.sum(target_labels))\n",
    "print(len(target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5473f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_v2(issues_embeddings,target_labels,batch_size):\n",
    "    \n",
    "    batch  = np.ndarray(shape = (batch_size,np.shape(issues_embeddings)[1]), dtype = np.float64)\n",
    "    labels = np.ndarray(shape = (batch_size,1), dtype = np.float64)\n",
    "    \n",
    "    seed(datetime.now())\n",
    "    \n",
    "    issues_to_use = random.sample([i for i in range(np.shape(issues_embeddings)[0])],batch_size)\n",
    "    \n",
    "    for counter,value in enumerate(issues_to_use):\n",
    "        batch[counter][:]  = issues_embeddings[value][:]\n",
    "        labels[counter,0] = target_labels.iloc[value]\n",
    "        \n",
    "    return batch,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_nn_v2(issues_embeddings,target_labels,hidden_layer_dim,learning_rate,\n",
    "                        batch_size,epochs,v_batch,v_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings)[1]])\n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,1])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings)[1],hidden_layer_dim],stddev = 1.0,dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0,dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,1],stddev = 1.0,dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([1],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    # neural network's functions\n",
    "    hidden_layer = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer = tf.nn.tanh(hidden_layer)\n",
    "    \n",
    "    output_layer  = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer2 = tf.nn.sigmoid(output_layer) \n",
    "    \n",
    "    #cost_func = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = Y_train,logits = output_layer2))\n",
    "    cost_func = tf.reduce_mean(-tf.log(output_layer2)*Y_train - (1-Y_train)*tf.log(1-output_layer2))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # generate batch.\n",
    "            batch_x,batch_y = generate_batch_v2(issues_embeddings,target_labels,batch_size)\n",
    "            # train the model\n",
    "            _,loss = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "            \n",
    "        \n",
    "        y_preds = sess.run(output_layer2,feed_dict = {X_train:v_batch,Y_train:v_labels})\n",
    "        for i in range(len(y_preds)):\n",
    "            print(y_preds[i],v_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues,train_labels,test_issues,test_labels = split_dataset(issues_embeddings,target_labels)\n",
    "v_batch  = np.reshape(test_issues,(-1,np.shape(issues_embeddings)[1]))\n",
    "v_labels = test_labels.to_numpy()\n",
    "v_labels = np.reshape(v_labels,(-1,1))\n",
    "preds = my_classifier_nn_v2(train_issues,train_labels,8,0.1,64,500,v_batch,v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2860a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
