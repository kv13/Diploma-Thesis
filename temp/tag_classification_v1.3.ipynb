{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc15fa6e",
   "metadata": {},
   "source": [
    "# Tag Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7026519",
   "metadata": {},
   "source": [
    "This notebook contains only implementations based on neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1d2d9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34376414",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "262a3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(path_to_file):\n",
    "    temp_dict = dict()\n",
    "    with open(path_to_file) as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            temp   = str(line)\n",
    "            values = temp.split(',')\n",
    "            temp_dict[values[0]] = int(values[1].replace(\"\\n\",\"\"))\n",
    "    \n",
    "    return temp_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "433f7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_issues(dir_path,tag_labels,descriptions,stack_traces):\n",
    "    \n",
    "    for fname in os.listdir(dir_path):\n",
    "        with open(os.path.join(dir_path,fname)) as json_file:\n",
    "            \n",
    "            data = json.load(json_file)\n",
    "            for issue in data:\n",
    "                \n",
    "                tags = issue['tags']\n",
    "                for i in range(len(tags)):\n",
    "                    tags[i] = tags[i].strip()\n",
    "                description = issue['description']\n",
    "                stack_trace = issue['stack_trace']\n",
    "                name        = issue['name']\n",
    "                \n",
    "                if tags != [] and stack_trace !=[] : #(description != [] or stack_trace != []):\n",
    "                    tag_labels.append(tags)\n",
    "                    descriptions.append(description)\n",
    "                    stack_traces.append(stack_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ee1bdf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from stack_trace_embedding notebook\n",
    "\n",
    "def clean_stack_trace(stack_trace):\n",
    "    \n",
    "    clean_stack_trace = []\n",
    "    temp_stack        = stack_trace.split(\" at \")[1:]\n",
    "    \n",
    "    to_find = re.compile(\"[|,|<|>]|/|\\|=\")\n",
    "    \n",
    "    #find where each function ends and keep only the path\n",
    "    for f in temp_stack:\n",
    "        temp      = f.find(')')\n",
    "        temp_file = f[0:temp]\n",
    "        \n",
    "        # check the punctuations in order to avoid anything else\n",
    "        match_obj = to_find.search(temp_file)\n",
    "        if match_obj == None:\n",
    "            filename = find_filename(temp_file)\n",
    "            if filename != '':\n",
    "                clean_stack_trace.append(filename)\n",
    "                \n",
    "    return clean_stack_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "02c987fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from stack_trace_embedding notebook\n",
    "\n",
    "def find_filename(value):\n",
    "    filename = \"\"\n",
    "    words    = value.split(\"(\")\n",
    "    if len(words)>=2:\n",
    "        parts = words[0].split(\".\")\n",
    "        filename = \".\".join(parts[0:-1])\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e546faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from word embeddings notebook\n",
    "\n",
    "def clean_description(description):\n",
    "    \n",
    "    # define stop words\n",
    "    all_stopwords = set(stopwords.words('english'))\n",
    "    \n",
    "    #define translator to translate punctuation to white space\n",
    "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    \n",
    "    #join all lines into one sentence\n",
    "    sentence     = ' '.join(description)\n",
    "    \n",
    "    #translate punctuation\n",
    "    new_sentence = sentence.translate(translator)\n",
    "    \n",
    "    #split the sentense in words\n",
    "    words = new_sentence.split()\n",
    "    \n",
    "    words_sw = [w.lower() for w in words if not w.lower() in all_stopwords and len(w)>1]\n",
    "    \n",
    "    return words_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3f7425c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste from word embeddings notebook\n",
    "\n",
    "def stemming_data(descriptions):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for desc in descriptions:\n",
    "        for counter in range(len(desc)):\n",
    "            if desc[counter].isalpha():\n",
    "                desc[counter] = stemmer.stem(desc[counter])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ace7ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(descriptions,stack_traces,use_stemming):\n",
    "    \n",
    "    clean_descriptions = list()\n",
    "    clean_stack_traces = list()\n",
    "    \n",
    "    for i in range(len(descriptions)):\n",
    "        \n",
    "        temp_desc   = descriptions[i]\n",
    "        temp_trace  = stack_traces[i]\n",
    "        stack_trace = []\n",
    "        clean_desc  = []\n",
    "        \n",
    "        if temp_trace != []:\n",
    "            if len(temp_trace)>1:\n",
    "                stack_trace = clean_stack_trace(' '.join(temp_trace))\n",
    "            else:\n",
    "                stack_trace = clean_stack_trace(temp_trace[0])\n",
    "            \n",
    "        if temp_desc  != []:\n",
    "            clean_desc = clean_description(temp_desc)\n",
    "            \n",
    "        clean_descriptions.append(clean_desc)\n",
    "        clean_stack_traces.append(stack_trace)\n",
    "            \n",
    "    if use_stemming == True:\n",
    "        stemming_data(clean_descriptions)\n",
    "        \n",
    "    return clean_descriptions,clean_stack_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e75f3",
   "metadata": {},
   "source": [
    "## Compute Arithmetic Representations for Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "79aa9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(arithmetic_descriptions,arithmetic_stack_traces,\n",
    "                       word_embedding_matrix,stack_embedding_matrix,use_words,use_stacks):\n",
    "    \n",
    "    total_embeddings_dim = 0\n",
    "    descriptions_dim     = 0\n",
    "    stack_traces_dim     = 0\n",
    "    \n",
    "    if use_words == True:\n",
    "        descriptions_dim     = np.shape(word_embedding_matrix)[1]\n",
    "        total_embeddings_dim = total_embeddings_dim + descriptions_dim\n",
    "        \n",
    "    if use_stacks == True:\n",
    "        stack_traces_dim     = np.shape(stack_embedding_matrix)[1]\n",
    "        total_embeddings_dim = total_embeddings_dim + stack_traces_dim\n",
    "    \n",
    "    # make sure that in any case there are something to compute\n",
    "    if total_embeddings_dim ==0:\n",
    "        return None\n",
    "    \n",
    "    num_issues        = len(arithmetic_descriptions)\n",
    "    issues_embeddings = np.zeros((num_issues,total_embeddings_dim))\n",
    "    \n",
    "    for counter in range(len(arithmetic_descriptions)):\n",
    "        \n",
    "        temp_desc   = arithmetic_descriptions[counter]\n",
    "        temp_stack  = arithmetic_stack_traces[counter]\n",
    "        total_words = 0\n",
    "        total_funcs = 0\n",
    "        \n",
    "        if use_words == True:\n",
    "            for word in temp_desc:\n",
    "                if word != -2:\n",
    "                    total_words += 1\n",
    "                    issues_embeddings[counter][0:descriptions_dim] = issues_embeddings[counter][0:descriptions_dim] + word_embedding_matrix[word]\n",
    "            if total_words != 0 :\n",
    "                issues_embeddings[counter]    /= total_words\n",
    "        \n",
    "        \n",
    "        if use_stacks == True:\n",
    "            for func in temp_stack:\n",
    "                if func != -2:\n",
    "                    issues_embeddings[counter][descriptions_dim:] = issues_embeddings[counter][descriptions_dim:] + stack_embedding_matrix[func]\n",
    "                    total_funcs += 1\n",
    "            if total_funcs != 0:\n",
    "                issues_embeddings[counter][descriptions_dim:] = issues_embeddings[counter][descriptions_dim:] / total_funcs \n",
    "            \n",
    "    return issues_embeddings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9557ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stemming = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "181d9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word embeddings\n",
    "word_embedding_matrix = np.loadtxt('../results/word_embeddings_g.txt', dtype=np.float64)\n",
    "\n",
    "# load stack traces embeddings \n",
    "stack_embedding_matrix = np.loadtxt('../results/stack_embeddings_g.txt', dtype=np.float64)\n",
    "\n",
    "# load vocabularies\n",
    "word2id_path = \"../outputs/words_vocabulary_g.txt\"\n",
    "func2id_path = \"../outputs/stacktraces_vocabulary_g.txt\"\n",
    "\n",
    "word2id = load_dict(word2id_path)\n",
    "func2id = load_dict(func2id_path)\n",
    "\n",
    "#load tags and descriptions\n",
    "dir_path     = '../data'\n",
    "tag_labels   = list()\n",
    "descriptions = list()\n",
    "stack_traces = list()\n",
    "\n",
    "# load issues\n",
    "load_issues(dir_path,tag_labels,descriptions,stack_traces)\n",
    "\n",
    "# transform data to arithmetic representation\n",
    "clean_descriptions,clean_stack_traces = clean_data(descriptions,stack_traces,use_stemming)\n",
    "\n",
    "clean_descriptions_2 = list()\n",
    "clean_stack_traces_2 = list()\n",
    "clean_tags_2         = list()\n",
    "\n",
    "# remove empty stack traces\n",
    "for counter,value in enumerate(clean_stack_traces):\n",
    "    if value != []:\n",
    "        clean_stack_traces_2.append(value)\n",
    "        clean_descriptions_2.append(clean_descriptions[counter])\n",
    "        clean_tags_2.append(tag_labels[counter])\n",
    "\n",
    "del clean_descriptions\n",
    "del clean_stack_traces\n",
    "\n",
    "del descriptions\n",
    "del stack_traces\n",
    "\n",
    "#arithmetic_transformations\n",
    "arithmetic_descriptions = [[word2id.get(word,-2) for word in desc]   for desc in clean_descriptions_2]\n",
    "arithmetic_stack_traces = [[func2id.get(func,-2) for func in trace] for trace in clean_stack_traces_2]\n",
    "\n",
    "del clean_descriptions_2\n",
    "del clean_stack_traces_2\n",
    "\n",
    "issues_embeddings  = compute_embeddings(arithmetic_descriptions,arithmetic_stack_traces,\n",
    "                                        word_embedding_matrix,stack_embedding_matrix,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "055d7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_labels = list()\n",
    "# copy by reference in order to avoid to change every where the variable name\n",
    "tag_labels = clean_tags_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fbc32954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['Bug','Google Play or Beta feedback','Prio - High']\n",
    "no_tags = 3\n",
    "np_tags = np.zeros((len(arithmetic_descriptions),no_tags))\n",
    "\n",
    "for counter in range(len(tag_labels)):\n",
    "    for counter_2,value in enumerate(tags):\n",
    "        if value in tag_labels[counter]:\n",
    "            np_tags[counter][counter_2] = 1\n",
    "            \n",
    "df_tags = pd.DataFrame(np_tags, columns = tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ff595629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(issues_embeddings,tags_order,df_tags,min_train_size=50,min_valid_size=10):\n",
    "    \n",
    "    # train issues\n",
    "    train_embeddings = np.ndarray(shape = (len(tags_order)*min_train_size,np.shape(issues_embeddings)[1]),\n",
    "                                  dtype = np.float64)\n",
    "    train_labels     = np.zeros(shape = (len(tags_order)*min_train_size,3),dtype = np.float64)\n",
    "    \n",
    "    # valid issues\n",
    "    valid_embeddings = np.ndarray(shape = (len(tags_order)*min_valid_size,np.shape(issues_embeddings)[1]),\n",
    "                                  dtype = np.float64)\n",
    "    valid_labels     = np.zeros(shape = (len(tags_order)*min_valid_size,3),dtype = np.float64)\n",
    "    \n",
    "    idxs             = list()\n",
    "    \n",
    "    for tag in tags_order:\n",
    "        temp = df_tags[tag]\n",
    "        idxs.append([i for i in range(len(temp)) if temp.loc[i] == 1])\n",
    "        \n",
    "    # make sure every index belongs only in one category.\n",
    "    for counter,value in enumerate(idxs):\n",
    "        if counter == len(idxs)-1:\n",
    "            break\n",
    "        for idx in value:\n",
    "            for counter_2 in range(counter+1,len(idxs)):\n",
    "                if idx in idxs[counter_2]:\n",
    "                    idxs[counter_2].remove(idx)\n",
    "    \n",
    "    #choose random indexes.\n",
    "    for counter,value in enumerate(idxs):\n",
    "        \n",
    "        random_idx_train = random.sample(value,min_train_size)\n",
    "        random_idx_valid = random.sample([i for i in value if i not in random_idx_train],min_valid_size)\n",
    "        \n",
    "        # training\n",
    "        temp_2 = 0\n",
    "        for temp in range(counter*min_train_size,(counter+1)*min_train_size):\n",
    "            \n",
    "            train_embeddings[temp]          = issues_embeddings[random_idx_train[temp_2]]\n",
    "            train_labels[temp][counter]     = 1.0\n",
    "            temp_2                         += 1\n",
    "        \n",
    "        # validation\n",
    "        temp_2 = 0\n",
    "        for temp in range(counter*min_valid_size,(counter+1)*min_valid_size):\n",
    "            valid_embeddings[temp]      = issues_embeddings[random_idx_valid[temp_2]]\n",
    "            valid_labels[temp][counter] = 1.0\n",
    "            temp_2                     += 1\n",
    "            \n",
    "    return train_embeddings,train_labels,valid_embeddings,valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6fbc6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_order = ['Prio - High','Google Play or Beta feedback','Bug']\n",
    "train_embeddings,train_labels,valid_embeddings,valid_labels = create_dataset(issues_embeddings,tags_order,df_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "65eb7a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.53837738e-02  2.74418837e-02  6.22628313e-02 -1.56801105e-01\n",
      "  5.83719625e-02  1.66944137e-02 -3.53333763e-02 -3.30767737e-02\n",
      "  1.04235540e-01  1.05979136e-01 -3.16425675e-02 -7.80891988e-02\n",
      "  3.32454888e-02 -9.15766362e-02  5.74351125e-03 -2.53142551e-01\n",
      " -4.38213975e-02 -9.63149088e-02 -4.25256437e-02  6.54376400e-02\n",
      "  3.95858537e-02  7.69956513e-02  3.31359450e-02 -6.88989638e-02\n",
      " -7.92653375e-03  1.48226077e-01 -3.74944500e-03 -3.82247500e-04\n",
      " -2.00725279e-01 -1.32207168e-01  1.44855864e-01  1.31241305e-01\n",
      "  5.05856162e-02  7.67247100e-02  4.12717050e-02 -4.87932800e-02\n",
      " -1.67940788e-02  6.64467125e-03  6.79226850e-02 -5.20381437e-02\n",
      " -1.05757820e-01  1.25942634e-01  3.69145987e-02  5.23231463e-02\n",
      "  3.01095153e-01  2.71505413e-02 -8.04947500e-03 -1.40164065e-01\n",
      " -1.74248021e-01 -1.75244011e-01  2.85760175e-02  2.61515112e-02\n",
      "  1.48000625e-03  4.78068388e-02  6.50094087e-02 -1.63009258e-01\n",
      "  8.75526500e-03 -4.37158987e-02 -1.24541637e-02  8.13168200e-02\n",
      " -1.00003361e-01  1.48545662e-02 -1.17227831e-01 -1.13239232e-01\n",
      " -4.36925489e-01 -1.40763600e-02  3.98797061e-01 -5.67055014e-02\n",
      "  3.90025997e-01  5.83963891e-01 -2.01100914e-02  1.93714674e-01] [1. 0. 0.]\n",
      "[ 1.95748167e-02 -5.52585583e-02  1.46119700e-02 -1.32674722e-01\n",
      " -1.68654683e-02  6.77135583e-02 -3.95022000e-02 -2.76742483e-02\n",
      "  1.41968773e-01  6.24889150e-02 -2.25359883e-02 -1.01172983e-02\n",
      "  1.80121520e-01 -9.90769683e-02  2.20829250e-02 -2.61737070e-01\n",
      "  5.56975317e-02 -2.56708183e-02 -8.25950217e-02 -5.33323450e-02\n",
      "  5.76905883e-02  3.99635850e-02  5.02326117e-02 -4.15888500e-02\n",
      " -4.19165467e-02  1.35433603e-01 -3.64215000e-04 -3.27374067e-02\n",
      " -2.31164318e-01 -1.14474450e-01  6.62246050e-02  1.13076173e-01\n",
      "  1.88299550e-02  1.02977012e-01  9.74337033e-02 -5.33020800e-02\n",
      "  2.73604983e-02  6.82852600e-02  3.53187917e-02 -5.38857033e-02\n",
      " -9.30768267e-02  1.27881572e-01  1.57115550e-02 -2.96692617e-02\n",
      "  2.59862293e-01 -7.18398117e-02 -3.30525133e-02 -3.03244267e-02\n",
      " -1.08511708e-01 -1.01693630e-01 -7.07028667e-02  5.65856067e-02\n",
      "  6.93400067e-02  3.33095467e-02  1.01471253e-01 -7.23002533e-02\n",
      "  4.97762933e-02  5.40921700e-02 -8.34008600e-02  1.42755622e-01\n",
      " -5.58165933e-02  9.10591183e-02 -1.03596842e-01 -1.61937918e-01\n",
      " -4.66034335e-01  2.75018039e-01  9.87679022e-02 -3.88012157e-01\n",
      "  3.05615102e-01  4.07388132e-01  2.02669969e-01 -1.27067038e-01] [1. 0. 0.]\n",
      "[ 0.06438246 -0.01022686  0.02992879 -0.14539175  0.00180148  0.05367205\n",
      " -0.02309352 -0.04642384  0.02490068  0.05764437 -0.06643995 -0.07193858\n",
      "  0.0635018  -0.08856655  0.00981239 -0.29350542 -0.01409758 -0.09723755\n",
      "  0.03448796  0.00748291  0.01763627  0.07152566  0.05967526 -0.03202399\n",
      " -0.02934331  0.15153147  0.01251267 -0.014613   -0.21045772 -0.13710763\n",
      "  0.10796256  0.18327294  0.03267556  0.10589521  0.0558021  -0.01108252\n",
      " -0.01750856  0.02971673  0.04982429 -0.00724133 -0.0617354   0.16396848\n",
      "  0.05853103  0.01448156  0.3186394   0.00866745 -0.00511188 -0.0735469\n",
      " -0.16134907 -0.17335333 -0.05278858  0.06194766  0.02314009  0.04970215\n",
      "  0.10515845 -0.15131146  0.003453    0.04938864 -0.01297427  0.09007754\n",
      " -0.03362422  0.01799139 -0.1589074  -0.10458397 -0.49894102  0.27856317\n",
      "  0.18278024 -0.03708267  0.48892364  0.19586194  0.02809497  0.17170462] [1. 0. 0.]\n",
      "[ 0.06288944  0.01764045  0.01033697 -0.18818979  0.00580508  0.04418076\n",
      " -0.09272902 -0.05001926 -0.01987595  0.01276574 -0.03885977 -0.05156427\n",
      "  0.08451482 -0.05725822  0.07365216 -0.29116807 -0.00585808 -0.1156948\n",
      "  0.05148142 -0.00065356  0.01382178  0.01420395  0.10489086 -0.02707956\n",
      "  0.02014094  0.11351178  0.01901866 -0.0530151  -0.17302735 -0.15370532\n",
      "  0.13480031  0.18853975  0.02517866  0.12086952  0.0964655   0.02084722\n",
      "  0.02973265  0.02447525  0.04321655 -0.05217182 -0.0308223   0.17572795\n",
      "  0.03242098  0.06410574  0.29706213  0.01321402  0.00227588 -0.08622144\n",
      " -0.14244486 -0.17217082 -0.04541722  0.07517448  0.02459468  0.01716902\n",
      "  0.07150498 -0.14961825 -0.04846483  0.0691346  -0.00647196  0.14379782\n",
      " -0.06098585  0.02972036 -0.10033163 -0.06881765 -0.31496952  0.12357251\n",
      "  0.33818729 -0.4865282   0.3399709   0.00146315  0.06749075 -0.00245768] [1. 0. 0.]\n",
      "[ 8.93636927e-02 -3.37105500e-02  4.65576091e-02 -1.94516985e-01\n",
      " -1.79112964e-02  4.60755836e-02 -1.89888645e-02 -1.56710836e-02\n",
      "  2.94101555e-02  4.81185591e-02 -6.10338645e-02 -8.69000391e-02\n",
      "  9.47998727e-03 -5.83924345e-02  2.13238709e-02 -2.73139955e-01\n",
      "  8.76067636e-03 -6.49106500e-02  2.15667109e-02 -7.21088636e-03\n",
      "  2.09772955e-02  7.70571918e-02  4.55371236e-02 -9.56071173e-02\n",
      " -3.50565364e-02  1.09179062e-01 -3.16897218e-02 -4.61569273e-03\n",
      " -1.95459515e-01 -1.32137264e-01  9.41185918e-02  1.40535733e-01\n",
      "  5.39271455e-03  9.10647255e-02  8.49820973e-02 -4.10044364e-02\n",
      " -1.86349036e-02  2.01800909e-04  9.00332300e-02 -4.09270900e-02\n",
      " -6.35449218e-02  1.51777692e-01  5.66844091e-02  3.29815709e-02\n",
      "  2.71242723e-01  4.24586909e-03 -1.96152673e-02 -1.06149681e-01\n",
      " -1.83313237e-01 -1.05406748e-01 -6.08728618e-02  1.28067125e-01\n",
      "  4.13505791e-02  5.59145509e-02  1.02152049e-01 -1.52490589e-01\n",
      "  4.37167055e-02  4.78677991e-02 -1.32543491e-02  8.40569200e-02\n",
      " -5.90384382e-02  5.33470291e-02 -9.73194855e-02 -9.89014564e-02\n",
      " -4.25328887e-01  2.86589163e-01  2.50918542e-01 -4.10413000e-01\n",
      "  2.65042180e-01  3.67260922e-01  1.67946635e-01  1.14459370e-01] [1. 0. 0.]\n",
      "[ 6.83992102e-02 -1.52149449e-03  3.25553898e-02 -7.91915000e-02\n",
      " -6.65792718e-02  9.18002439e-02 -2.22134467e-02 -3.32650682e-02\n",
      "  5.13743878e-04  7.78569484e-02 -3.62260245e-02 -4.00043388e-03\n",
      "  1.00331679e-01 -4.87688273e-02  2.80630763e-02 -2.99878550e-01\n",
      "  6.10332347e-03 -9.84704259e-02  4.27717543e-02 -9.85824122e-03\n",
      "  3.71721567e-02  8.94753624e-02  5.89399637e-02 -1.49083731e-02\n",
      "  4.00101347e-03  1.64304126e-01  4.14601186e-02 -7.78389184e-04\n",
      " -2.35881151e-01 -1.19591320e-01  8.04390457e-02  2.23574602e-01\n",
      "  2.14289473e-02  1.12331371e-01  2.81594137e-02 -2.29986563e-02\n",
      "  1.44301957e-02  3.88259786e-02  4.37516233e-02 -4.25614535e-02\n",
      " -8.36793741e-02  1.54898292e-01  2.00336869e-02  3.02180318e-02\n",
      "  3.40815871e-01  3.18021867e-02  1.94838657e-02 -5.84537380e-02\n",
      " -2.07094769e-01 -1.81616259e-01 -9.26310410e-02  8.90936210e-02\n",
      "  2.98164627e-02  3.28682898e-02  7.50471655e-02 -1.45884390e-01\n",
      "  3.39230620e-02  6.55074153e-02 -9.85219939e-03  7.85639888e-02\n",
      " -4.52216563e-02  3.06273624e-02 -1.16608392e-01 -1.23331992e-01\n",
      " -5.36387390e-01  2.46392675e-01  3.26559033e-02 -1.81648180e-01\n",
      "  4.45226172e-01  4.22188412e-01  1.78794164e-01  4.75884117e-02] [1. 0. 0.]\n",
      "[ 0.0682357  -0.00303979  0.06120723 -0.08438816 -0.01481683  0.08143564\n",
      " -0.02526338 -0.04799259  0.06115013  0.05485765 -0.04626425 -0.03488222\n",
      "  0.05518687 -0.05386086 -0.00854403 -0.27574677  0.01491854 -0.07909076\n",
      "  0.00211996 -0.00470174  0.06172238  0.04032431  0.07651982 -0.04383033\n",
      "  0.01469438  0.15940598  0.03308157  0.05506242 -0.20875607 -0.10842899\n",
      "  0.05203743  0.18003305  0.03620601  0.1217301   0.08972217 -0.01985342\n",
      "  0.0366582   0.05477596  0.05036606 -0.02743164 -0.07590091  0.1544312\n",
      "  0.01355098  0.01103053  0.28487701  0.00890243 -0.02173457 -0.0747854\n",
      " -0.15683598 -0.14318554 -0.05495367  0.05577219  0.01262422  0.03409299\n",
      "  0.12514923 -0.14742734  0.03425812  0.07072764  0.01290724  0.07633111\n",
      " -0.06066357  0.02320384 -0.09808568 -0.08967576 -0.49564622  0.2550903\n",
      "  0.1072212  -0.1788542   0.4679224   0.2796555   0.3212607  -0.13541284] [1. 0. 0.]\n",
      "[ 0.04483681  0.00667031  0.04885224 -0.15392385 -0.08962005  0.06132892\n",
      " -0.0584404  -0.05334332  0.00928938  0.00144121 -0.07194154 -0.03301513\n",
      "  0.04531077 -0.05744469  0.04848585 -0.2200267  -0.01614763 -0.08435485\n",
      " -0.00660334 -0.02715469  0.02205891  0.08347195  0.12045403 -0.04943246\n",
      " -0.02326498  0.12938728  0.01756013 -0.03571913 -0.1854331  -0.143578\n",
      "  0.09781003  0.14817075  0.010806    0.07543338  0.03319767 -0.04986687\n",
      "  0.01078185  0.02647743  0.06995523 -0.0777487  -0.06331341  0.16272211\n",
      "  0.04686516  0.01754278  0.28892942 -0.01352206 -0.02179818 -0.0600374\n",
      " -0.17189273 -0.17417366 -0.03135866  0.07051304  0.03256635  0.07484592\n",
      "  0.0776185  -0.09804251  0.0131769   0.08142563 -0.00895713  0.08476602\n",
      " -0.06721849  0.05385443 -0.11286677 -0.07293329 -0.46695647  0.21896591\n",
      " -0.00678889 -0.33600962  0.36231812  0.47104595  0.2804357  -0.01732172] [1. 0. 0.]\n",
      "[ 0.07768228 -0.02618932  0.07971896 -0.14901521 -0.01667707  0.05493722\n",
      "  0.02689406  0.01920124  0.03400159 -0.00225246 -0.01127172  0.02051538\n",
      "  0.0360664  -0.10428614  0.05541438 -0.23710548 -0.01715405 -0.0777355\n",
      "  0.00836632  0.00442843  0.01073642  0.068169    0.07053033 -0.07533634\n",
      " -0.00197448  0.20290799  0.01665152  0.0338578  -0.22694525 -0.13412993\n",
      "  0.12163557  0.14506029  0.04642553  0.0924705   0.00347479 -0.04376895\n",
      " -0.01180068  0.02577366  0.06533148 -0.07553387 -0.09679472  0.17001909\n",
      "  0.03521749  0.01170893  0.30859731  0.03581963 -0.04250546 -0.07779721\n",
      " -0.23239015 -0.12698611 -0.07458142  0.03112721  0.07900253  0.05395461\n",
      "  0.09768744 -0.15972522  0.01654138  0.01707694  0.0223203   0.00616178\n",
      " -0.0363603   0.04244192 -0.15332496 -0.13779463 -0.39967691  0.25393987\n",
      " -0.07359101 -0.41531758  0.43649156  0.14639921  0.3145383  -0.00669012] [1. 0. 0.]\n",
      "[ 0.19222275  0.05470514  0.00607832 -0.13830085  0.02095007  0.05291399\n",
      "  0.1505899  -0.05943671  0.0066434   0.10160946 -0.06436759 -0.06199197\n",
      " -0.0114832  -0.06295797 -0.01496735 -0.21364132 -0.00168853 -0.07268482\n",
      " -0.07395493 -0.00374803  0.00099363  0.05042266 -0.00739747 -0.12138219\n",
      " -0.03252488  0.19149461 -0.01963901  0.06892302 -0.17670117 -0.120769\n",
      "  0.13647894  0.1604901   0.03342416  0.04416243  0.08279617 -0.06341785\n",
      " -0.0757095   0.04700121  0.04071862 -0.09752801 -0.13072936  0.16993559\n",
      "  0.0353662   0.00310654  0.26386856  0.04713402 -0.02224461 -0.07844418\n",
      " -0.19474713 -0.14188715 -0.03122049  0.14031033  0.05133085  0.12097493\n",
      "  0.1458856  -0.23967379 -0.0074819  -0.08788957 -0.07113833  0.05125\n",
      " -0.09601444  0.01599437 -0.10396617 -0.10083119 -0.41302749  0.11585709\n",
      "  0.29251471 -0.46505215  0.25001571  0.17669064  0.16944081  0.02225505] [1. 0. 0.]\n",
      "[ 0.07786811  0.02337992  0.10877836 -0.14138061  0.04667141  0.04294179\n",
      "  0.00150086 -0.00767728  0.03177396  0.0598641  -0.04353165 -0.00316099\n",
      "  0.03411364 -0.11154659  0.0463604  -0.23373177 -0.0383521  -0.12870023\n",
      " -0.00233955  0.00218015  0.00997008  0.06935698  0.05747562 -0.07098805\n",
      " -0.02878429  0.16369679  0.06813419  0.0392239  -0.16693231 -0.09452244\n",
      "  0.11404757  0.1187811   0.04410979  0.05559147  0.0062709  -0.02461132\n",
      " -0.01591266  0.00783512  0.00663029 -0.01184243 -0.07324462  0.14433017\n",
      "  0.03296509  0.01761062  0.30291466 -0.05437895  0.02527336 -0.1143963\n",
      " -0.18516435 -0.11386669 -0.01721857  0.0668816   0.04697792  0.05085635\n",
      "  0.08257917 -0.19603124 -0.0612034   0.01326345  0.03563205  0.06032178\n",
      " -0.09702852  0.05459319 -0.14287016 -0.08349219 -0.39011631  0.20364911\n",
      "  0.21918533 -0.54648587  0.24577282  0.16013743  0.0552288   0.01900636] [0. 1. 0.]\n",
      "[ 0.0915694  -0.08491507  0.0652102  -0.12154774  0.00391141  0.06531713\n",
      " -0.01877593 -0.07717818 -0.01051515  0.04053259 -0.0019288   0.00547182\n",
      "  0.09226896 -0.12865569  0.04743538 -0.25176331  0.02798972 -0.10829331\n",
      " -0.0244896   0.0229193   0.00521892  0.02653439  0.06371856 -0.06691781\n",
      "  0.0205677   0.11915     0.05077891  0.01735848 -0.17886944 -0.17813527\n",
      "  0.05841697  0.16798593 -0.01218631  0.06600516 -0.01682035 -0.05075545\n",
      "  0.02302789  0.03158453  0.06311373 -0.0558652  -0.07958913  0.13785953\n",
      "  0.03361467  0.05972519  0.26474515  0.03124984 -0.01759256 -0.08429551\n",
      " -0.16389913 -0.11970954 -0.07208793  0.11001238  0.11110734  0.0728879\n",
      "  0.06978216 -0.20279238 -0.00243244 -0.02811147  0.02993311  0.09138082\n",
      " -0.02711571  0.0420562  -0.13058521 -0.10349458 -0.55777123  0.25694607\n",
      "  0.04747694 -0.06865486  0.47004944  0.30937275  0.22697247 -0.03682967] [0. 1. 0.]\n",
      "[ 0.08321557 -0.02587599  0.05119677 -0.13399348 -0.08174076  0.0338149\n",
      " -0.03845694 -0.03260866  0.02898194 -0.03767265 -0.01014722 -0.01199777\n",
      "  0.07082443 -0.1032096   0.03212481 -0.23004952 -0.04665302 -0.11925529\n",
      "  0.00708561 -0.03772117  0.00972104  0.0602615   0.08175266 -0.05154605\n",
      " -0.03338663  0.1258947   0.01976074  0.00562604 -0.18617885 -0.12137878\n",
      "  0.0557235   0.18967069  0.04643305  0.05992413  0.03925017  0.02099212\n",
      "  0.00295806  0.00412957  0.07423183 -0.04260304 -0.09197386  0.20346792\n",
      "  0.03942586  0.05595548  0.29691565  0.01269021 -0.03383285 -0.03817266\n",
      " -0.14875999 -0.16763428 -0.04583473  0.07411343  0.0401994   0.02636361\n",
      "  0.06563707 -0.11691333 -0.00762473  0.07463542  0.01808976  0.11059252\n",
      " -0.06617265  0.04476856 -0.08734985 -0.05777018 -0.48472334  0.17426352\n",
      "  0.02036815 -0.29778039  0.33726349  0.45020558  0.3239801  -0.02701815] [0. 1. 0.]\n",
      "[ 0.11925144 -0.00077919  0.06187944 -0.15581043  0.00744274  0.0478537\n",
      " -0.01396175 -0.04348209  0.03274746  0.03053597 -0.01782682 -0.05374371\n",
      "  0.06000375 -0.09388334  0.04549343 -0.25956522 -0.01525303 -0.09968556\n",
      " -0.009808   -0.03675002  0.0163396   0.06064239  0.06750683 -0.04843922\n",
      " -0.00528734  0.1349794   0.0299141   0.01305731 -0.1920985  -0.12688514\n",
      "  0.1033897   0.18237533  0.03269817  0.07705976  0.09523876  0.01839111\n",
      "  0.01122985  0.01590235  0.0661769  -0.06313295 -0.06826639  0.13570994\n",
      "  0.04382858  0.03417041  0.27881927  0.03020197 -0.05117276 -0.0885925\n",
      " -0.13167132 -0.16025633 -0.06257769  0.07013254  0.02510145  0.0235026\n",
      "  0.07983162 -0.13326845  0.03407337  0.01072371  0.00164283  0.07429726\n",
      " -0.0654257   0.02589059 -0.11068653 -0.12043429 -0.35589589  0.23834611\n",
      "  0.38234017 -0.4840142   0.38706979 -0.23605864  0.13896191  0.24036322] [0. 1. 0.]\n",
      "[ 2.00879033e-01 -8.87199500e-02  6.23007367e-02 -1.16751320e-01\n",
      "  8.21346167e-02  2.63844967e-02  1.73633253e-01 -8.08330000e-02\n",
      "  5.37678333e-02  1.57692150e-01 -4.60011000e-03 -1.93020567e-02\n",
      " -2.22494900e-02 -1.68400177e-01 -3.74839500e-02 -2.42530420e-01\n",
      "  5.65454767e-02 -1.66397167e-02 -4.38349533e-02  4.57709467e-02\n",
      " -8.19523333e-02  4.01856233e-02 -5.76880800e-02 -1.38639430e-01\n",
      "  1.52055667e-03  1.95004200e-01 -2.65483967e-02  3.15212400e-02\n",
      " -2.10751713e-01 -1.21011410e-01  1.30722903e-01  1.10702243e-01\n",
      "  4.48601133e-02  8.92676667e-02 -5.52371433e-02 -9.22843400e-02\n",
      " -9.61372233e-02  8.33352567e-02 -2.55133333e-05 -5.62458733e-02\n",
      " -1.17869203e-01  1.10266160e-01  6.06415600e-02 -1.78645767e-02\n",
      "  2.72169903e-01  9.31899933e-02 -4.17175167e-02 -7.74475033e-02\n",
      " -2.22052607e-01 -1.20862283e-01 -6.53420300e-02  9.74708767e-02\n",
      "  6.56419833e-02  1.06537987e-01  1.54283130e-01 -2.57169410e-01\n",
      " -2.00325133e-02 -1.07338857e-01  2.76371967e-02 -9.71270000e-04\n",
      " -8.43456433e-02  6.85935567e-02 -1.57162443e-01 -1.47849570e-01\n",
      " -4.94488892e-01  2.25043921e-01 -6.77876077e-03 -2.09548273e-01\n",
      "  4.30569323e-01  4.07719599e-01  2.74037990e-01  1.23601436e-01] [0. 1. 0.]\n",
      "[ 0.08138554  0.01915711  0.06413387 -0.13850843  0.00827635  0.0565149\n",
      "  0.04875007 -0.03906162  0.02135411  0.06704569 -0.02777529 -0.03508065\n",
      "  0.03667162 -0.13529986  0.06910615 -0.28379168 -0.00224268 -0.09726753\n",
      " -0.00693987  0.02412895  0.02472855  0.08208833  0.02245725 -0.0906204\n",
      "  0.05300934  0.17628655  0.02465536  0.06091679 -0.18167887 -0.15302906\n",
      "  0.09578996  0.14882983  0.04198906  0.08369246  0.00339106 -0.02704839\n",
      " -0.02187195  0.03956288  0.05360186 -0.03005936 -0.10471572  0.14948195\n",
      "  0.02409753  0.00127159  0.29605679  0.02220961  0.02469663 -0.13504925\n",
      " -0.2060376  -0.15653466 -0.04052631  0.03869549  0.05572959  0.07730557\n",
      "  0.08617602 -0.18999809 -0.00164956 -0.02963512  0.02245842  0.06019395\n",
      " -0.08673899  0.02621366 -0.13883834 -0.10921379 -0.25623517  0.17423709\n",
      "  0.08434782 -0.53422576  0.41074962  0.4104399  -0.02802369  0.08350324] [0. 1. 0.]\n",
      "[ 1.54865672e-01 -5.30282075e-02  8.51970575e-02 -8.27072900e-02\n",
      "  1.17019367e-01  1.40752752e-01  1.25866415e-01 -4.76209250e-02\n",
      "  4.17138100e-02  1.00090400e-01 -3.94093625e-02 -3.43772875e-02\n",
      "  8.02631750e-03 -1.87507367e-01  3.76085000e-03 -2.01636792e-01\n",
      "  3.88753850e-02 -7.48557200e-02  2.50517500e-04  4.43651325e-02\n",
      "  5.52920000e-04  1.00435687e-01  4.57509400e-02 -7.19261175e-02\n",
      "  4.35501125e-02  1.51005612e-01  2.59678500e-03  1.02857735e-01\n",
      " -1.96350457e-01 -1.57134082e-01  1.10704858e-01  1.51514175e-01\n",
      "  7.61494175e-02  7.13280725e-02 -6.56278775e-02 -7.58567475e-02\n",
      " -1.11695287e-01  7.06358450e-02  2.48059100e-02 -5.24213850e-02\n",
      " -1.06279827e-01  1.51280052e-01  7.94563500e-03 -1.37582150e-02\n",
      "  2.81679745e-01  9.76328975e-02  1.22670800e-02 -1.10312730e-01\n",
      " -2.30148620e-01 -1.02108895e-01 -1.09790115e-01  1.22006090e-01\n",
      "  3.68763150e-02  8.73570550e-02  7.65358900e-02 -2.29259437e-01\n",
      " -4.46899000e-03 -1.30773518e-01  1.36505575e-02 -2.14359500e-02\n",
      " -1.44793312e-01  1.80976500e-02 -1.34690083e-01 -1.41717543e-01\n",
      " -5.84837966e-01  2.05154819e-01  2.81077440e-02 -1.07751782e-01\n",
      "  3.28497663e-01  2.26686654e-01  4.30771153e-01  1.33515483e-01] [0. 1. 0.]\n",
      "[ 8.30599841e-02 -2.27528630e-03  2.49621304e-02 -1.44892811e-01\n",
      " -2.48837119e-02  3.56683415e-02  1.02632378e-02 -8.89362963e-03\n",
      "  3.63501519e-03  3.52649815e-03 -4.90205007e-02 -5.15809237e-02\n",
      "  6.07465689e-02 -1.10280813e-01  6.95639919e-02 -2.48627922e-01\n",
      "  9.12977037e-04 -1.07167156e-01 -1.07537296e-02 -4.61512811e-02\n",
      "  4.58226200e-02  6.35335419e-02  3.98211374e-02 -7.35529200e-02\n",
      "  3.92544926e-03  1.50685480e-01  2.88136778e-03  7.00997889e-03\n",
      " -1.83517073e-01 -1.41382554e-01  8.88826537e-02  1.88132897e-01\n",
      "  3.51447148e-02  7.48098389e-02  3.59332037e-02 -2.54258459e-02\n",
      " -1.22083641e-02  3.55636444e-02  7.68159274e-02 -5.15138363e-02\n",
      " -8.00936252e-02  1.82300906e-01  3.53416952e-02  2.29483244e-02\n",
      "  2.87335888e-01  5.04553937e-02 -3.66956485e-02 -9.29924500e-02\n",
      " -2.17808603e-01 -1.34419390e-01 -5.45220659e-02  6.95075344e-02\n",
      "  6.13118196e-02  5.70561900e-02  9.66817715e-02 -1.74686100e-01\n",
      "  4.28812222e-04  4.64928593e-03  2.52282130e-02  4.74447296e-02\n",
      " -6.09057970e-02  2.46121037e-02 -1.39949644e-01 -9.80419411e-02\n",
      " -4.79962074e-01  1.52712751e-01  2.98617447e-02 -3.14195774e-01\n",
      "  3.28532879e-01  1.37014891e-01  3.88283678e-01  1.05774711e-02] [0. 1. 0.]\n",
      "[ 7.67579034e-02 -7.61121586e-03  3.85780845e-02 -1.73948132e-01\n",
      " -3.88239500e-02  4.53079031e-02 -7.93502966e-03 -3.57102345e-02\n",
      "  1.31381124e-02  1.91702024e-02 -6.18516786e-02 -4.89157883e-02\n",
      "  5.80834448e-02 -1.02100238e-01  2.57834514e-02 -2.48955983e-01\n",
      " -2.25195907e-02 -1.12063808e-01 -9.20418034e-03 -4.27514417e-02\n",
      "  3.11417634e-02  6.11408579e-02  3.58038862e-02 -4.89103359e-02\n",
      " -6.67101345e-03  1.32885625e-01  3.70234359e-02 -4.43642414e-04\n",
      " -2.01080307e-01 -1.58811761e-01  9.40496793e-02  1.78403064e-01\n",
      "  4.53004562e-02  6.60168534e-02  1.73765576e-02 -2.78291407e-02\n",
      "  1.12985345e-03  3.52711359e-02  8.32743976e-02 -3.30693362e-02\n",
      " -6.86265976e-02  1.69152276e-01  2.92357634e-02  1.67218141e-02\n",
      "  3.08146709e-01  4.86727655e-03 -2.22712459e-02 -4.96703724e-02\n",
      " -1.63421998e-01 -1.73180432e-01 -6.33128990e-02  8.22895672e-02\n",
      "  1.84365366e-02  3.44060738e-02  1.10884056e-01 -1.40615050e-01\n",
      "  1.57191124e-02  2.53454207e-02  2.01122845e-02  7.79575686e-02\n",
      " -5.27821472e-02  6.11819838e-02 -1.12552615e-01 -1.02407509e-01\n",
      " -5.71706377e-01  2.38913570e-01  8.01094334e-02 -2.64103742e-01\n",
      "  2.58291314e-01  3.83612900e-01  2.74835587e-01 -9.57690695e-02] [0. 1. 0.]\n",
      "[ 8.47565637e-02 -4.34480388e-02  5.73307413e-02 -1.69558900e-01\n",
      "  5.21312650e-02  4.97129637e-02  4.58569213e-02 -7.41754213e-02\n",
      " -3.62898750e-04  9.45501662e-02 -4.23665663e-02 -3.19300125e-02\n",
      "  3.40047725e-02 -1.46372541e-01  3.75111075e-02 -2.56308498e-01\n",
      " -1.20905738e-02 -1.35715608e-01  8.84093125e-03  1.37402500e-02\n",
      "  1.18987413e-02  4.65277675e-02  7.62841588e-02 -7.46727163e-02\n",
      " -1.78082538e-02  1.60137251e-01  2.08415313e-02  1.15580625e-03\n",
      " -2.03674126e-01 -1.44243389e-01  9.84794825e-02  1.51485631e-01\n",
      "  2.37489412e-02  8.80584612e-02  3.77900900e-02 -1.75822175e-02\n",
      " -4.84424037e-02  3.33698250e-03  1.22012587e-02 -2.67403487e-02\n",
      " -1.00444478e-01  1.60229735e-01  2.93112200e-02  6.09383250e-03\n",
      "  3.05579964e-01  4.27720975e-02  1.27482975e-02 -9.90753913e-02\n",
      " -1.43680176e-01 -1.42455445e-01 -2.21154075e-02  1.24813156e-01\n",
      "  2.02056038e-02  7.76855463e-02  1.01705971e-01 -1.78200165e-01\n",
      " -1.45134188e-02 -6.23891200e-02 -1.90355525e-02  6.78767538e-02\n",
      " -1.01244407e-01  2.53152325e-02 -1.48091049e-01 -9.64858700e-02\n",
      " -7.33294890e-01  2.79602988e-01  1.45603170e-01 -3.09325012e-01\n",
      "  1.02634775e-01  6.96964050e-02  3.19755185e-01  1.59548810e-01] [0. 1. 0.]\n",
      "[ 6.53364686e-02 -3.96535157e-02  6.61303835e-02 -1.66918804e-01\n",
      " -2.28861878e-02  3.26034289e-02 -5.54711132e-02 -3.65579232e-02\n",
      "  4.12222300e-02  4.97416357e-02 -2.63259849e-02 -6.83723473e-02\n",
      "  5.29705605e-02 -1.25378890e-01  3.21131976e-02 -2.55099750e-01\n",
      " -1.50651200e-02 -8.97326168e-02 -6.19331892e-04  4.12045676e-03\n",
      " -1.57041427e-02  4.72969146e-02  6.25342143e-02 -4.72410335e-02\n",
      " -1.50769354e-02  1.37738249e-01 -1.11476835e-02 -4.53833405e-03\n",
      " -2.07901756e-01 -1.24977026e-01  6.35438924e-02  1.41844948e-01\n",
      "  6.25088854e-02  9.56013603e-02  4.39602789e-02  1.22934773e-02\n",
      " -5.37012405e-03  1.99216435e-02  1.63605773e-02 -1.36213019e-02\n",
      " -4.77023138e-02  1.15528342e-01  2.85516132e-02  1.30927603e-02\n",
      "  2.61103761e-01 -7.10835919e-03 -1.66897727e-02 -6.65723243e-02\n",
      " -1.46998406e-01 -1.92937972e-01 -3.41975884e-02  6.78653608e-02\n",
      "  3.67660030e-02  2.68879019e-02  7.46221249e-02 -1.38499153e-01\n",
      " -6.78342459e-03  3.89706089e-02 -2.67240216e-03  9.46763019e-02\n",
      " -3.78462251e-02  2.85575670e-02 -1.37220504e-01 -7.55965438e-02\n",
      " -6.25112291e-01  1.14183746e-01  6.13778410e-01 -8.04020025e-02\n",
      "  1.21424256e-01 -1.38608066e-01  2.58187711e-01  2.97771825e-02] [0. 0. 1.]\n",
      "[ 0.07642172 -0.02229363 -0.13182658 -0.15713854  0.05650056 -0.01894612\n",
      " -0.02998351 -0.0978547   0.31494099  0.14433679 -0.01371749 -0.26379612\n",
      "  0.02457438 -0.18274683 -0.23846    -0.130813    0.02300842 -0.02059241\n",
      " -0.1713815  -0.19682708  0.0035946   0.18200061  0.2014419  -0.03754653\n",
      " -0.20022847  0.02687337 -0.10803788  0.0085109   0.1059394  -0.08591571\n",
      "  0.02719204  0.01866895 -0.04838555  0.00127459  0.00252505  0.03940558\n",
      " -0.12650786 -0.0995414   0.20516585  0.0802512  -0.03292486  0.04282044\n",
      "  0.21500443  0.12944525  0.1658887  -0.02428395  0.0382537  -0.17447793\n",
      " -0.27546746 -0.09158521  0.01425654  0.10696924  0.07449406 -0.0106974\n",
      "  0.15320653 -0.2698693  -0.01222859  0.00394858  0.01483357  0.0346777\n",
      " -0.01762168  0.04464361  0.02227983 -0.12968551 -0.44726196  0.18777969\n",
      "  0.02823952 -0.44874693  0.25274887  0.46039598  0.29153592 -0.03840201] [0. 0. 1.]\n",
      "[ 0.04043998  0.0045524   0.0377333  -0.167524   -0.01059928  0.08482703\n",
      "  0.0237413  -0.05591219  0.019345    0.04520459  0.00624874 -0.04078268\n",
      "  0.03178577 -0.10445628  0.01565752 -0.26000145 -0.01267154 -0.0776644\n",
      "  0.00638679  0.00693443 -0.0228362   0.05803412  0.01481173 -0.05315235\n",
      "  0.02413143  0.13385002  0.05471153  0.00315712 -0.2430532  -0.11634661\n",
      "  0.09162166  0.20359129  0.06277851  0.09281612  0.0487178  -0.05412873\n",
      " -0.05523739  0.03690692  0.04408835 -0.0446793  -0.01959915  0.21171524\n",
      "  0.04982104  0.00862836  0.3074006   0.01110979  0.00486703 -0.07683207\n",
      " -0.18220065 -0.15225441 -0.07352795  0.04483331  0.0411549   0.1185843\n",
      "  0.12737329 -0.09858121  0.02619423  0.01969136 -0.02461159  0.10562493\n",
      " -0.06005556  0.02116085 -0.12289539 -0.13477846 -0.57634956  0.18075082\n",
      "  0.01477003 -0.16649668  0.28577744  0.15508924  0.52061063  0.07890654] [0. 0. 1.]\n",
      "[ 0.05075365 -0.01466951  0.02176789 -0.21725619 -0.02569438  0.00500318\n",
      " -0.09161086  0.0240308   0.00262186 -0.0156846  -0.03039072 -0.02090427\n",
      "  0.12524132 -0.05365412  0.06928853 -0.23305072  0.03858317 -0.07337619\n",
      "  0.06028478  0.02407547  0.02856889  0.0841661   0.10566463 -0.07708742\n",
      " -0.01846829  0.16665299  0.04087604 -0.05731822 -0.18168265 -0.19688967\n",
      "  0.09885588  0.15487404  0.06016085  0.18480629  0.18221045  0.04559811\n",
      "  0.03226826 -0.01565562  0.03441431  0.00724291 -0.03833053  0.12580674\n",
      "  0.00306398  0.04860398  0.27092366 -0.01237642 -0.06999638 -0.03451813\n",
      " -0.14048283 -0.17932959 -0.04137802  0.12417779  0.05181304 -0.01033732\n",
      "  0.06425498 -0.14072771  0.08178233  0.10409039 -0.02368159  0.15568349\n",
      "  0.01584979  0.03527831 -0.16647741 -0.02408536  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ] [0. 0. 1.]\n",
      "[ 0.06003731 -0.01314978  0.01630127 -0.14589416 -0.04483476  0.06327343\n",
      " -0.03153305 -0.04442779 -0.01935412  0.0282793  -0.0493304  -0.04289186\n",
      "  0.10086532 -0.07374195  0.03523686 -0.28058034 -0.00749586 -0.11004527\n",
      "  0.02156897 -0.00070314  0.01790777  0.10029946  0.08282739 -0.02378178\n",
      "  0.01807705  0.13865787  0.0399693  -0.01259003 -0.22855588 -0.14230618\n",
      "  0.06375286  0.205651    0.02570226  0.06763246  0.05024287  0.00368172\n",
      "  0.02341395  0.02236126  0.08062239 -0.0202947  -0.06447998  0.17176448\n",
      "  0.03390605  0.03510758  0.32379483  0.01870409  0.00758402 -0.07207893\n",
      " -0.19099346 -0.16436767 -0.0502485   0.0972618   0.00892363  0.03765876\n",
      "  0.10909713 -0.14895719 -0.00393322  0.04283328 -0.00531645  0.08168196\n",
      " -0.05534985  0.03383736 -0.12143298 -0.09481101 -0.43627794  0.18399265\n",
      " -0.05923516 -0.43811259  0.29581396  0.24735602  0.39911652  0.09618425] [0. 0. 1.]\n",
      "[ 1.97444467e-02 -1.23313739e-02  4.11075767e-02 -1.39413428e-01\n",
      " -5.90461104e-02  5.19428585e-02 -5.39870007e-02 -4.71710212e-02\n",
      "  8.37211951e-04  5.49911957e-02 -5.09579163e-02 -1.94332221e-02\n",
      "  1.05122146e-01 -3.50146405e-02  4.02495734e-02 -2.91672420e-01\n",
      " -4.68770610e-04 -8.86344098e-02  6.49439112e-02  1.39592952e-02\n",
      " -1.57445351e-02  7.19313716e-02  6.25837779e-02 -2.55300496e-02\n",
      " -1.49419590e-02  1.44060483e-01  2.95187278e-02 -2.16568190e-02\n",
      " -2.38985918e-01 -1.58268800e-01  7.30091144e-02  2.06323596e-01\n",
      "  2.84389232e-02  1.26894834e-01  8.10229138e-02 -1.37281738e-02\n",
      "  1.81050579e-02  1.35264005e-02  5.71685672e-02 -2.26617526e-02\n",
      " -7.79743617e-02  1.48388733e-01  2.95087137e-02  3.86083859e-02\n",
      "  3.47306935e-01  1.60974541e-02  3.99467817e-03 -6.59344729e-02\n",
      " -1.96494212e-01 -1.91113882e-01 -6.12135272e-02  9.27073270e-02\n",
      "  4.03347466e-02  2.57363621e-02  8.17349890e-02 -1.13465823e-01\n",
      "  3.78470582e-02  6.68698991e-02 -1.51991055e-02  9.33203696e-02\n",
      " -4.92423048e-02  4.60125490e-02 -1.13461370e-01 -1.14322921e-01\n",
      " -5.48956094e-01  1.94633408e-01  1.28814617e-02 -2.82238290e-01\n",
      "  2.10911973e-01  3.83520331e-01  3.27649568e-01  1.08568642e-01] [0. 0. 1.]\n",
      "[ 5.12813300e-02 -4.37842470e-02  4.55731260e-02 -1.87240796e-01\n",
      " -3.23813810e-02  3.17450240e-02 -4.42461560e-02 -9.55053940e-02\n",
      "  3.15473000e-03  7.03168950e-02 -4.18894870e-02 -4.09778810e-02\n",
      "  8.06036630e-02  2.38183800e-03 -1.04332350e-02 -2.36052178e-01\n",
      " -4.52490020e-02 -1.14446714e-01  4.16365230e-02  2.18702790e-02\n",
      " -1.42220260e-02  7.39745450e-02  8.01259730e-02 -1.57589870e-02\n",
      " -6.33983260e-02  1.74876501e-01  2.15473000e-04 -2.17501520e-02\n",
      " -2.28386836e-01 -1.85491674e-01  6.78339420e-02  1.79088760e-01\n",
      "  6.46114140e-02  1.08776652e-01  1.06162326e-01  7.17955800e-03\n",
      "  3.57283050e-02 -9.58673000e-03  7.99484900e-02 -8.33873350e-02\n",
      " -8.34143480e-02  1.28407759e-01  7.84808700e-03  3.99090560e-02\n",
      "  3.00290025e-01 -1.19019610e-02 -1.43681980e-02 -2.30848040e-02\n",
      " -1.13874255e-01 -2.13756793e-01 -4.80159710e-02  7.71482990e-02\n",
      "  3.22430260e-02  1.21479220e-02  8.74311830e-02 -9.99329450e-02\n",
      " -7.21803390e-02  7.36524270e-02 -1.78073110e-02  8.37875490e-02\n",
      " -6.74361100e-02  2.69585360e-02 -1.09976439e-01 -6.20985880e-02\n",
      " -4.72910275e-01  2.00612877e-01 -4.05509560e-02 -3.15193797e-01\n",
      "  3.66767564e-01  2.76164503e-01  4.28564184e-01 -6.80559595e-02] [0. 0. 1.]\n",
      "[ 8.00238056e-02 -1.32149719e-02  6.71061688e-02 -1.27397291e-01\n",
      " -5.49323994e-02  6.70315375e-02 -1.25353444e-02 -6.10656494e-02\n",
      "  1.96024100e-02  3.08740544e-02 -4.35758425e-02 -1.55970944e-02\n",
      "  7.70293688e-02 -8.52278144e-02  2.85177875e-03 -2.77340295e-01\n",
      " -1.08155494e-02 -1.16428048e-01 -2.38162225e-02 -4.51808125e-04\n",
      "  1.14920319e-02  3.25083219e-02  6.45346125e-02 -4.98290081e-02\n",
      " -2.62923087e-02  1.66498699e-01  4.08568338e-02 -7.53795500e-03\n",
      " -2.19459812e-01 -1.30400668e-01  8.85019275e-02  1.44892474e-01\n",
      "  3.69328619e-02  1.06905446e-01  6.55194669e-02 -2.56604519e-02\n",
      "  2.98407981e-02  1.98827081e-02  2.93151919e-02 -1.47108850e-02\n",
      " -6.98580681e-02  1.49250948e-01  2.94062187e-02  2.17555125e-02\n",
      "  2.69192447e-01 -5.84995125e-03 -2.72905906e-02 -6.67834550e-02\n",
      " -1.51036261e-01 -1.72001027e-01 -3.18420294e-02  9.02142425e-02\n",
      "  4.93708969e-02  3.53875325e-02  6.56803838e-02 -1.67900260e-01\n",
      " -1.85217269e-02  2.55818856e-02  3.98431119e-02  7.70277400e-02\n",
      " -5.49524831e-02  5.65826856e-02 -1.17135799e-01 -8.17103044e-02\n",
      " -4.74097176e-01  2.38068259e-01  1.33721450e-02 -3.54640436e-01\n",
      "  3.37156085e-01  4.72638911e-01  2.86425197e-01 -3.84180819e-02] [0. 0. 1.]\n",
      "[ 4.60363942e-02  1.05736596e-02  7.32984742e-02 -1.29691557e-01\n",
      " -2.77292836e-02  8.42624600e-02 -4.25996624e-02 -4.89345518e-02\n",
      "  2.01209356e-02  3.60858631e-02 -6.60235622e-03 -1.17671549e-02\n",
      "  6.72363622e-02 -9.90478840e-02  2.22338018e-02 -2.75912999e-01\n",
      " -8.95721467e-03 -8.91360100e-02  4.27748089e-03  7.12879244e-03\n",
      "  3.16311447e-02  6.88030447e-02  7.14551489e-02 -5.84696949e-02\n",
      "  5.40432867e-03  1.51261328e-01  3.23306431e-02  1.37993916e-02\n",
      " -2.28359469e-01 -1.49660664e-01  9.63190496e-02  2.06763378e-01\n",
      "  3.21514487e-02  1.00024118e-01  4.79691184e-02  4.46059067e-03\n",
      "  4.38176000e-04  3.61579991e-02  4.17154213e-02 -2.09442122e-02\n",
      " -7.09344720e-02  1.59729982e-01  1.36085169e-02 -9.18891689e-03\n",
      "  3.09313699e-01  1.51797640e-02  2.00745082e-02 -9.48934707e-02\n",
      " -1.84982114e-01 -1.51647935e-01 -5.33296762e-02  5.50544169e-02\n",
      "  1.94895951e-02  6.47655522e-02  7.20581142e-02 -1.28809747e-01\n",
      " -1.59159222e-03  6.60479262e-02  6.09302244e-03  9.12055456e-02\n",
      " -5.37396458e-02  4.54196364e-02 -1.14200097e-01 -1.14226715e-01\n",
      " -4.61144874e-01  2.46680131e-01 -8.44146286e-03 -3.30821690e-01\n",
      "  4.41449053e-01  4.74991623e-01  1.97275764e-01 -2.12303986e-02] [0. 0. 1.]\n",
      "[ 0.10484171  0.02622326  0.05194581 -0.12332998 -0.0387909   0.08256994\n",
      " -0.03385637 -0.03401775  0.05378588  0.05547321 -0.00812877 -0.05368023\n",
      "  0.07734486 -0.0950698  -0.01129855 -0.21659    -0.01377432 -0.06305234\n",
      "  0.01907702  0.02999142  0.02271454  0.03516855  0.06337213 -0.03754531\n",
      " -0.029109    0.1568806  -0.00338005  0.01427088 -0.18573977 -0.16728195\n",
      "  0.05587251  0.17689945  0.02452898  0.08061688  0.02606865 -0.0265979\n",
      "  0.00748769  0.0071533   0.06257664 -0.06458213 -0.09732149  0.13220108\n",
      "  0.03006549  0.05775822  0.24862336 -0.00209819  0.01258029 -0.0847571\n",
      " -0.17055032 -0.16323218 -0.05608758  0.06646314  0.00258122  0.04753731\n",
      "  0.08965437 -0.15333863  0.00493394  0.04797924  0.00742896  0.07318816\n",
      " -0.11145589  0.02121872 -0.13054865 -0.12137874 -0.48131793  0.21081179\n",
      " -0.03912458 -0.27507614  0.43387525  0.41911069  0.29306191  0.03863256] [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(np.shape(valid_embeddings)[0]):\n",
    "    print(valid_embeddings[i],valid_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c227dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     1.0\n",
      "Name: 292, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     1.0\n",
      "Name: 79, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     1.0\n",
      "Name: 300, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     1.0\n",
      "Name: 74, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     1.0\n",
      "Name: 222, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     1.0\n",
      "Name: 397, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     1.0\n",
      "Name: 144, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     1.0\n",
      "Name: 21, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     1.0\n",
      "Name: 105, dtype: float64\n",
      "[1. 0. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     1.0\n",
      "Name: 95, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 402, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 358, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             0.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 440, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 424, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 355, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 63, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 17, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 75, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 347, dtype: float64\n",
      "[0. 1. 0.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    1.0\n",
      "Prio - High                     0.0\n",
      "Name: 117, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 392, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 263, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 325, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 197, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 155, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 304, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 290, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 123, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 182, dtype: float64\n",
      "[0. 0. 1.]\n",
      "Bug                             1.0\n",
      "Google Play or Beta feedback    0.0\n",
      "Prio - High                     0.0\n",
      "Name: 128, dtype: float64\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "slack = 0\n",
    "for i in range(np.shape(valid_embeddings)[0]):\n",
    "    issue_embedding = valid_embeddings[i]\n",
    "    issue_labels    = valid_labels[i]\n",
    "    for counter,temp_embedding in enumerate(issues_embeddings):\n",
    "        comp = temp_embedding==issue_embedding\n",
    "        if comp.all() == True:\n",
    "            slack += 1\n",
    "            print(issue_labels)\n",
    "            print(df_tags.loc[counter])\n",
    "print(slack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675393a8",
   "metadata": {},
   "source": [
    "## Neural Network Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a26ab18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26fb42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset2(issues_embeddings,target_labels,t_size =0.1):\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits = 1, test_size = t_size, random_state = 0)\n",
    "    \n",
    "    X_train_0 = list()\n",
    "    X_train_1 = list()\n",
    "    \n",
    "    for train_index, test_index in sss.split(issues_embeddings,target_labels):\n",
    "        #X_train,X_test = issues_embeddings[train_index], issues_embeddings[test_index]\n",
    "        #Y_train,Y_test = target_labels[train_index], target_labels[test_index]\n",
    "        \n",
    "        \n",
    "        X_test = issues_embeddings[test_index]\n",
    "        Y_test = target_labels[test_index]\n",
    "        \n",
    "        for index in train_index:\n",
    "            if target_labels.iloc[index] == 0:\n",
    "                X_train_0.append(issues_embeddings[index])\n",
    "            elif target_labels.iloc[index] == 1:\n",
    "                X_train_1.append(issues_embeddings[index])\n",
    "                \n",
    "    return X_train_0,X_train_1,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d5b22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(issues_embeddings,target_labels,batch_size):\n",
    "    \n",
    "    batch  = np.ndarray(shape = (batch_size,np.shape(issues_embeddings)[1]), dtype = np.float64)\n",
    "    labels = np.ndarray(shape = (batch_size,2), dtype = np.float64)\n",
    "    \n",
    "    issues_to_use = random.sample([i for i in range(np.shape(issues_embeddings)[0])],batch_size)\n",
    "    \n",
    "    for counter,value in enumerate(issues_to_use):\n",
    "        batch[counter][:]  = issues_embeddings[value][:]\n",
    "        # label_0\n",
    "        labels[counter][0] = 1-target_labels.iloc[value]\n",
    "        # label_1\n",
    "        labels[counter][1] =   target_labels.iloc[value]\n",
    "    return batch,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dce3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(issues_embeddings_0, issues_embeddings_1, batch_size):\n",
    "    \n",
    "    batch  = np.ndarray(shape = (batch_size,np.shape(issues_embeddings_0)[1]), dtype = np.float64)\n",
    "    labels = np.ndarray(shape = (batch_size,2), dtype = np.float64)\n",
    "    \n",
    "    issues_to_use_0 = random.sample([i for i in range(np.shape(issues_embeddings_0)[0])],batch_size//2)\n",
    "    issues_to_use_1 = random.sample([i for i in range(np.shape(issues_embeddings_1)[0])],batch_size//2)\n",
    "    \n",
    "    # even indexes for issues belong to class 0\n",
    "    # odd  indexes for issues belong to class 1\n",
    "    counter_0 = 0\n",
    "    counter_1 = 0\n",
    "    \n",
    "    for counter in range(batch_size):\n",
    "        \n",
    "        # even indexes\n",
    "        if counter%2 == 0 :\n",
    "            batch[counter][:]  = issues_embeddings_0[issues_to_use_0[counter_0]][:]\n",
    "            labels[counter][0] = 1\n",
    "            labels[counter][1] = 0\n",
    "            counter_0 += 1\n",
    "        else:\n",
    "            batch[counter][:]  = issues_embeddings_1[issues_to_use_1[counter_1]][:]\n",
    "            labels[counter][0] = 0\n",
    "            labels[counter][1] = 1\n",
    "            counter_1 += 1\n",
    "            \n",
    "    return batch,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc899dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(y_probs,v_labels):\n",
    "    \n",
    "    y_probs_1 = np.ndarray(shape = (np.shape(v_labels)[0],1), dtype = np.float64)\n",
    "    y_preds_1 = np.ndarray(shape = (np.shape(v_labels)[0],1), dtype = np.float64)\n",
    "    y_true_1  = np.ndarray(shape = (np.shape(v_labels)[0],1), dtype = np.float64) \n",
    "    \n",
    "    for i in range(np.shape(v_labels)[0]):\n",
    "        y_true_1[i]  = v_labels[i][1]\n",
    "        y_preds_1[i] = 0 if y_probs[i][0]>y_probs[i][1] else 1\n",
    "        y_probs_1[i] = y_probs[i][1]\n",
    "    \n",
    "    matrix_confusion = metrics.confusion_matrix(y_true=y_true_1,y_pred=y_preds_1)\n",
    "    \n",
    "    return y_probs_1, y_preds_1, y_true_1, matrix_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfed1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(y_true,y_probs):\n",
    "    \n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y_true,y_probs)\n",
    "    auc                = metrics.auc(fpr,tpr)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe169dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(total_confusion,aucs):\n",
    "    \n",
    "    acc = (total_confusion[0][0]+total_confusion[1][1])/np.sum(total_confusion)\n",
    "    \n",
    "    gm  = np.sqrt((total_confusion[0][0]/(total_confusion[0][0]+total_confusion[0][1]))*\n",
    "              (total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])))\n",
    "    \n",
    "    pre = total_confusion[1][1]/(total_confusion[1][1]+total_confusion[1][0])\n",
    "    \n",
    "    mean_auc = np.sum(aucs)/np.shape(aucs)[0]\n",
    "\n",
    "    print(\"accuracy\" , acc)\n",
    "    print(\"precision\", pre)\n",
    "    print(\"GM\"       , gm)\n",
    "    print(\"mean auc\" , mean_auc)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ca19b",
   "metadata": {},
   "source": [
    "#### First and Simpliest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25a6b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_nn2(issues_embeddings_0,issues_embeddings_1,hidden_layer_dim,\n",
    "                      learning_rate,batch_size,epochs,v_batch,v_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings_0)[1]])\n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,2])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings_0)[1],hidden_layer_dim],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0/ math.sqrt(hidden_layer_dim),dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    # hidden-output layer variables\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,2],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([2],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    # neural network's functions\n",
    "    hidden_layer   = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer   = tf.nn.tanh(hidden_layer)\n",
    "     \n",
    "    output_layer   = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer_2 = tf.nn.softmax(output_layer)\n",
    "    \n",
    "    cost_func = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # generate batch.\n",
    "            batch_x,batch_y = pooling(issues_embeddings_0,issues_embeddings_1,batch_size)\n",
    "            \n",
    "            # train the model\n",
    "            _,loss = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "        \n",
    "        # saving the weights in numpy format\n",
    "        #W1_np = W1.eval()\n",
    "        #b1_np = b1.eval()\n",
    "        #W2_np = W2.eval()\n",
    "        #b2_np = b2.eval()\n",
    "        \n",
    "        \n",
    "        # validation\n",
    "        y_probs     = sess.run(output_layer_2,feed_dict={X_train:v_batch,Y_train:v_labels})\n",
    "    \n",
    "    return compute_predictions(y_probs,v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8665a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91b087b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "# first implementation the simpliest neural network\n",
    "# use both word embeddings and stack traces embeddings.\n",
    "\n",
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bb5833e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7195652173913043\n",
      "precision 0.7073170731707317\n",
      "GM 0.7615773105863908\n",
      "mean auc 0.8131707317073171\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_iterations = 10\n",
    "total_confusion  = np.zeros((2,2))\n",
    "conf_matrix      = np.zeros((2,2))\n",
    "aucs             = np.zeros(total_iterations)\n",
    "\n",
    "for i in range(total_iterations):\n",
    "    y_probs_1, _, y_true_1, conf_matrix = my_classifier_nn2(train_issues_0,train_issues_1,16,0.01,\n",
    "                                                            2*batch_size,100,v_batch,v_labels)\n",
    "    total_confusion = total_confusion + conf_matrix\n",
    "    aucs[i]         = compute_auc(y_true_1,y_probs_1)\n",
    "\n",
    "compute_metrics(total_confusion,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82965567",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5868d8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "target_labels = df_tags[\"Google Play or Beta feedback\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,\n",
    "                                                                      target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51c6e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8695652173913043\n",
      "precision 0.8235294117647058\n",
      "GM 0.8592652174945423\n",
      "mean auc 0.8993914807302232\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_iterations = 10\n",
    "total_confusion  = np.zeros((2,2))\n",
    "conf_matrix      = np.zeros((2,2))\n",
    "aucs             = np.zeros(total_iterations)\n",
    "\n",
    "for i in range(total_iterations):\n",
    "    y_probs_1, _, y_true_1, conf_matrix = my_classifier_nn2(train_issues_0,train_issues_1,32,0.01,\n",
    "                                                            2*batch_size,100,v_batch,v_labels)\n",
    "    total_confusion = total_confusion + conf_matrix\n",
    "    aucs[i]         = compute_auc(y_true_1,y_probs_1)\n",
    "\n",
    "compute_metrics(total_confusion,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad992bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ae54c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "target_labels = df_tags[\"Prio - High\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,\n",
    "                                                                      target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99bf8baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5478260869565217\n",
      "precision 0.475\n",
      "GM 0.51720402163943\n",
      "mean auc 0.537828947368421\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_iterations = 10\n",
    "total_confusion  = np.zeros((2,2))\n",
    "conf_matrix      = np.zeros((2,2))\n",
    "aucs             = np.zeros(total_iterations)\n",
    "\n",
    "for i in range(total_iterations):\n",
    "    y_probs_1, _, y_true_1, conf_matrix = my_classifier_nn2(train_issues_0,train_issues_1,4,0.01,\n",
    "                                                            2*batch_size,50,v_batch,v_labels)\n",
    "    total_confusion = total_confusion + conf_matrix\n",
    "    aucs[i]         = compute_auc(y_true_1,y_probs_1)\n",
    "    \n",
    "compute_metrics(total_confusion,aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5956856",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd91e1",
   "metadata": {},
   "source": [
    "Because the first implementation has big variances in scores between sequential trainings in the same training and testing datasets we will implement a ensemble technique in order to make the results more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c886743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions_voting(total_ypreds,total_nn):\n",
    "    \n",
    "    threshold = total_nn//2\n",
    "    ypreds    = np.ndarray(shape = (np.shape(total_ypreds)[0],1),dtype = np.float64)\n",
    "    \n",
    "    for i in range(np.shape(total_ypreds)[0]):\n",
    "        ypreds[i] = 0 if total_ypreds[i]<=threshold else 1\n",
    "    \n",
    "    return ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46ab8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "534ca867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "# voting technique based on the first and simpliest neural network.\n",
    "# Use odd number of nn so majority wins every time.\n",
    "\n",
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa30f9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7608695652173914\n",
      "precision 0.7560975609756098\n",
      "GM 0.7777390621413379\n",
      "mean auc 0.810840108401084\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_nn       = 9\n",
    "aucs           = np.zeros(total_nn)\n",
    "total_ypreds_1 = np.zeros(shape = (np.shape(v_labels)[0],1), dtype = np.float64)\n",
    "\n",
    "for i in range(total_nn):\n",
    "    y_probs_1, y_preds_1, y_true_1, conf_matrix = my_classifier_nn2(train_issues_0,train_issues_1,16,0.01,\n",
    "                                                                    2*batch_size,100,v_batch,v_labels)\n",
    "    total_ypreds_1    = total_ypreds_1 + y_preds_1 \n",
    "    aucs[i]           = compute_auc(y_true_1,y_probs_1)\n",
    "\n",
    "y_preds1         = compute_predictions_voting(total_ypreds_1,total_nn)\n",
    "matrix_confusion = metrics.confusion_matrix(y_true=y_true_1,y_pred=y_preds1)\n",
    "compute_metrics(matrix_confusion,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cede31",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2ed8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "target_labels = df_tags[\"Google Play or Beta feedback\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,\n",
    "                                                                      target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f161ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8913043478260869\n",
      "precision 0.8823529411764706\n",
      "GM 0.8894239994007015\n",
      "mean auc 0.9003831417624522\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_nn       = 9\n",
    "aucs           = np.zeros(total_nn)\n",
    "total_ypreds_1 = np.zeros(shape = (np.shape(v_labels)[0],1), dtype = np.float64)\n",
    "\n",
    "for i in range(total_nn):\n",
    "    y_probs_1, y_preds_1, y_true_1, conf_matrix = my_classifier_nn2(train_issues_0,train_issues_1,32,0.01,\n",
    "                                                                    2*batch_size,100,v_batch,v_labels)\n",
    "    total_ypreds_1    = total_ypreds_1 + y_preds_1\n",
    "    aucs[i]           = compute_auc(y_true_1,y_probs_1)\n",
    "    \n",
    "y_preds1         = compute_predictions_voting(total_ypreds_1,total_nn)\n",
    "matrix_confusion = metrics.confusion_matrix(y_true=y_true_1,y_pred=y_preds1)\n",
    "compute_metrics(matrix_confusion,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e400abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ee9c46d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "target_labels = df_tags[\"Prio - High\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,\n",
    "                                                                      target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "680f8ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5\n",
      "precision 0.625\n",
      "GM 0.5441071875825088\n",
      "mean auc 0.5303362573099416\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_nn       = 9\n",
    "aucs           = np.zeros(total_nn)\n",
    "total_ypreds_1 = np.zeros(shape = (np.shape(v_labels)[0],1), dtype = np.float64)\n",
    "\n",
    "for i in range(total_nn):\n",
    "    y_probs_1, y_preds_1, y_true_1, conf_matrix = my_classifier_nn2(train_issues_0,train_issues_1,4,0.01,\n",
    "                                                                    2*batch_size,100,v_batch,v_labels)\n",
    "    total_ypreds_1    = total_ypreds_1 + y_preds_1\n",
    "    aucs[i]           = compute_auc(y_true_1,y_probs_1)\n",
    "    \n",
    "y_preds1         = compute_predictions_voting(total_ypreds_1,total_nn)\n",
    "matrix_confusion = metrics.confusion_matrix(y_true=y_true_1,y_pred=y_preds1)\n",
    "compute_metrics(matrix_confusion,aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839cacc6",
   "metadata": {},
   "source": [
    "#### Patience remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1613870d",
   "metadata": {},
   "source": [
    "Here the neural network architecture is implemented based on patience remaining technique in order to avoid tuning the hyper parameter epochs and as a consequence avoid overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16b5b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e38b45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation(train_issues_0,train_issues_1,rate=0.1):\n",
    "    \n",
    "    new_train_issues_0 = list()\n",
    "    new_train_issues_1 = list()\n",
    "    validation_issues  = list()\n",
    "    validation_labels  = list()\n",
    "    \n",
    "    validation_size_0 = int(len(train_issues_0)*rate)\n",
    "    validation_size_1 = int(len(train_issues_1)*rate)\n",
    "    \n",
    "    validation_idxs_0 = random.sample([i for i in range(len(train_issues_0))], validation_size_0)\n",
    "    validation_idxs_1 = random.sample([i for i in range(len(train_issues_1))], validation_size_1)\n",
    "    \n",
    "    for i in range(len(train_issues_0)):\n",
    "        if i in validation_idxs_0:\n",
    "            validation_issues.append(train_issues_0[i])\n",
    "            validation_labels.append(0.0)\n",
    "        else:\n",
    "            new_train_issues_0.append(train_issues_0[i])\n",
    "    \n",
    "    for i in range(len(train_issues_1)):\n",
    "        if i in validation_idxs_1:\n",
    "            validation_issues.append(train_issues_1[i])\n",
    "            validation_labels.append(1.0)\n",
    "        else:\n",
    "            new_train_issues_1.append(train_issues_1[i])\n",
    "    \n",
    "    # create a pandas series for validation labels in order to be compatible with the rest code\n",
    "    val_labels_series = pd.Series(validation_labels, index = [i for i in range(len(validation_labels))])\n",
    "    \n",
    "    # create a np array for validation issues in order to be compatible with the rest code\n",
    "    val_issues = np.array(validation_issues)\n",
    "    \n",
    "    return new_train_issues_0,new_train_issues_1,val_issues,val_labels_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3715731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_nn3(issues_embeddings_0,issues_embeddings_1,hidden_layer_dim,\n",
    "                      learning_rate,batch_size,v_batch,v_labels,t_batch,t_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings_0)[1]])\n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,2])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings_0)[1],hidden_layer_dim],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                      dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    # hidden-output layer variables\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,2],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([2],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    # neural network's functions\n",
    "    hidden_layer   = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer   = tf.nn.tanh(hidden_layer)\n",
    "     \n",
    "    output_layer   = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer_2 = tf.nn.softmax(output_layer)\n",
    "    \n",
    "    cost_func = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    # patience mehtod's variables\n",
    "    min_loss = float('inf')\n",
    "    \n",
    "    min_W1             = np.zeros((np.shape(issues_embeddings_0)[1],hidden_layer_dim))\n",
    "    min_b1             = np.zeros(hidden_layer_dim)\n",
    "    min_W2             = np.zeros((hidden_layer_dim,2))\n",
    "    min_b2             = np.zeros(2)\n",
    "    patience_remaining = 100\n",
    "    step               = batch_size/(np.shape(issues_embeddings_0)[0] + np.shape(issues_embeddings_1)[0])\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(50000):\n",
    "            \n",
    "            # generate batch.\n",
    "            batch_x,batch_y = pooling(issues_embeddings_0,issues_embeddings_1,batch_size)\n",
    "            \n",
    "            # train the model\n",
    "            _,train_loss = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "            # maybe valid loss should not be cross entropy but better the predictions.\n",
    "            valid_loss   = sess.run(cost_func,feed_dict={X_train:v_batch,Y_train:v_labels})\n",
    "            \n",
    "            patience_remaining -= step\n",
    "            if valid_loss < min_loss:\n",
    "                min_loss           = valid_loss\n",
    "                patience_remaining = 100\n",
    "                min_W1             = W1.eval()\n",
    "                min_b1             = b1.eval()\n",
    "                min_W2             = W2.eval()\n",
    "                min_b2             = b2.eval()\n",
    "            if patience_remaining<=0:\n",
    "                print(\"total epochs\",epoch+1)\n",
    "                break\n",
    "        \n",
    "        # restore minimum weights\n",
    "        W1 = tf.convert_to_tensor(min_W1)\n",
    "        b1 = tf.convert_to_tensor(min_b1)\n",
    "        W2 = tf.convert_to_tensor(min_W2)\n",
    "        b2 = tf.convert_to_tensor(min_b2)\n",
    "                \n",
    "        # testing\n",
    "        y_probs     = sess.run(output_layer_2,feed_dict={X_train:t_batch,Y_train:t_labels})\n",
    "        \n",
    "    return compute_predictions(y_probs,t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3207212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "# use patience remaining technique\n",
    "\n",
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,target_labels,t_size=0.1)\n",
    "\n",
    "# create validation set\n",
    "train_issues_0,train_issues_1,valid_issues,valid_labels = create_validation(train_issues_0,train_issues_1)\n",
    "\n",
    "\n",
    "batch_size  = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "\n",
    "t_batch,t_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])\n",
    "v_batch,v_labels = generate_batch(valid_issues,valid_labels,np.shape(valid_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c45d609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epochs 591\n",
      "accuracy 0.6956521739130435\n",
      "precision 0.7073170731707317\n",
      "GM 0.6514524110803789\n",
      "mean auc 0.7707317073170732\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aucs = list()\n",
    "y_probs_1, y_preds_1, y_true_1, conf_matrix = my_classifier_nn3(train_issues_0,train_issues_1,16,0.01,\n",
    "                                                                2*batch_size,v_batch,v_labels,t_batch,t_labels)\n",
    "\n",
    "aucs.append(compute_auc(y_true_1,y_probs_1)) \n",
    "compute_metrics(conf_matrix,aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0f621",
   "metadata": {},
   "source": [
    "#### Drop Out layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a55f791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_nn4(issues_embeddings_0,issues_embeddings_1,hidden_layer_dim,\n",
    "                      learning_rate,batch_size,epochs,v_batch,v_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings_0)[1]])\n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,2])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings_0)[1],hidden_layer_dim],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0/ math.sqrt(hidden_layer_dim),dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    # hidden-output layer variables\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,2],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([2],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    # neural network's functions\n",
    "    hidden_layer   = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer   = tf.nn.tanh(hidden_layer)\n",
    "    \n",
    "    dropout_layer  = tf.nn.dropout(hidden_layer,rate = 0.5)\n",
    "    \n",
    "    output_layer   = tf.add(tf.matmul(dropout_layer,W2),b2)\n",
    "    \n",
    "    # for validation and testing dont use dropout\n",
    "    output_layer_all = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer_2   = tf.nn.softmax(output_layer_all)\n",
    "    \n",
    "    cost_func = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # generate batch.\n",
    "            batch_x,batch_y = pooling(issues_embeddings_0,issues_embeddings_1,batch_size)\n",
    "            \n",
    "            # train the model\n",
    "            _,loss = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "        \n",
    "        # validation\n",
    "        y_probs     = sess.run(output_layer_2,feed_dict={X_train:v_batch,Y_train:v_labels})\n",
    "    \n",
    "    return compute_predictions(y_probs,v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f399760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first implementation the simpliest neural network\n",
    "# use both word embeddings and stack traces embeddings.\n",
    "\n",
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,target_labels)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "v_batch,v_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "49a9087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.775\n",
      "precision 0.8333333333333334\n",
      "GM 0.45643546458763845\n",
      "mean auc 0.7013888888888888\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aucs = list()\n",
    "\n",
    "# for drop out neral network => hidden_layer_dim = hidden_layer_dim/rate, epochs are more\n",
    "y_probs_1, _, y_true_1, conf_matrix = my_classifier_nn4(train_issues_0,train_issues_1,64,0.01,\n",
    "                                                        2*batch_size,100,v_batch,v_labels)\n",
    "\n",
    "aucs.append(compute_auc(y_true_1,y_probs_1))\n",
    "compute_metrics(conf_matrix,aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b7a44",
   "metadata": {},
   "source": [
    "#### DropOut Layer + Patience Remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "007ebd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_nn5(issues_embeddings_0,issues_embeddings_1,hidden_layer_dim,\n",
    "                      learning_rate,batch_size,v_batch,v_labels,t_batch,t_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings_0)[1]])\n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,2])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings_0)[1],hidden_layer_dim],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0/ math.sqrt(hidden_layer_dim),dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    # hidden-output layer variables\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,2],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([2],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    # neural network's functions\n",
    "    hidden_layer   = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer   = tf.nn.tanh(hidden_layer)\n",
    "    \n",
    "    dropout_layer  = tf.nn.dropout(hidden_layer,rate = 0.5)\n",
    "    \n",
    "    output_layer   = tf.add(tf.matmul(dropout_layer,W2),b2)\n",
    "    \n",
    "    # for validation and testing dont use dropout\n",
    "    output_layer_all = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer_2   = tf.nn.softmax(output_layer_all)\n",
    "    \n",
    "    cost_func  = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer))\n",
    "    valid_func = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer_all))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    # patience mehtod's variables\n",
    "    min_loss = float('inf')\n",
    "    \n",
    "    min_W1             = np.zeros((np.shape(issues_embeddings_0)[1],hidden_layer_dim))\n",
    "    min_b1             = np.zeros(hidden_layer_dim)\n",
    "    min_W2             = np.zeros((hidden_layer_dim,2))\n",
    "    min_b2             = np.zeros(2)\n",
    "    \n",
    "    patience_remaining = 100\n",
    "    step               = batch_size/(np.shape(issues_embeddings_0)[0] + np.shape(issues_embeddings_1)[0])\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(50000):\n",
    "            \n",
    "            # generate batch.\n",
    "            batch_x,batch_y = pooling(issues_embeddings_0,issues_embeddings_1,batch_size)\n",
    "            \n",
    "            # train the model\n",
    "            _,loss     = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "            valid_loss = sess.run(valid_func,feed_dict={X_train:v_batch,Y_train:v_labels}) \n",
    "            \n",
    "            patience_remaining -= step\n",
    "            if valid_loss < min_loss:\n",
    "                min_loss           = valid_loss\n",
    "                patience_remaining = 100\n",
    "                min_W1             = W1.eval()\n",
    "                min_b1             = b1.eval()\n",
    "                min_W2             = W2.eval()\n",
    "                min_b2             = b2.eval()\n",
    "            if patience_remaining<=0:\n",
    "                print(\"total epochs\",epoch+1)\n",
    "                break\n",
    "        \n",
    "        # restore minimum weights\n",
    "        W1 = tf.convert_to_tensor(min_W1)\n",
    "        b1 = tf.convert_to_tensor(min_b1)\n",
    "        W2 = tf.convert_to_tensor(min_W2)\n",
    "        b2 = tf.convert_to_tensor(min_b2)\n",
    "        \n",
    "        # testing\n",
    "        y_probs     = sess.run(output_layer_2,feed_dict={X_train:t_batch,Y_train:t_labels})\n",
    "    \n",
    "    return compute_predictions(y_probs,t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1e8c9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "06f723e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "# use patience remaining technique\n",
    "\n",
    "target_labels = df_tags[\"Bug\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,target_labels,t_size=0.1)\n",
    "\n",
    "# create validation set\n",
    "train_issues_0,train_issues_1,valid_issues,valid_labels = create_validation(train_issues_0,train_issues_1)\n",
    "\n",
    "\n",
    "batch_size  = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "\n",
    "t_batch,t_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])\n",
    "v_batch,v_labels = generate_batch(valid_issues,valid_labels,np.shape(valid_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "363473f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epochs 768\n",
      "accuracy 0.6956521739130435\n",
      "precision 0.6829268292682927\n",
      "GM 0.7391491482878365\n",
      "mean auc 0.775609756097561\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aucs = list()\n",
    "y_probs_1, y_preds_1, y_true_1, conf_matrix = my_classifier_nn5(train_issues_0,train_issues_1,32,0.01,\n",
    "                                                                2*batch_size,v_batch,v_labels,t_batch,t_labels)\n",
    "\n",
    "aucs.append(compute_auc(y_true_1,y_probs_1)) \n",
    "compute_metrics(conf_matrix,aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "15b34a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "target_labels = df_tags[\"Prio - High\"]\n",
    "train_issues_0,train_issues_1,test_issues,test_labels = split_dataset2(issues_embeddings,target_labels,t_size=0.1)\n",
    "\n",
    "# create validation set\n",
    "train_issues_0,train_issues_1,valid_issues,valid_labels = create_validation(train_issues_0,train_issues_1)\n",
    "\n",
    "batch_size = np.shape(train_issues_0)[0] if np.shape(train_issues_0)[0]<np.shape(train_issues_1)[0] else np.shape(train_issues_1)[0]  \n",
    "print(batch_size)\n",
    "\n",
    "t_batch,t_labels = generate_batch(test_issues,test_labels,np.shape(test_issues)[0])\n",
    "v_batch,v_labels = generate_batch(valid_issues,valid_labels,np.shape(valid_issues)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "36e18805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epochs 316\n",
      "accuracy 0.5869565217391305\n",
      "precision 0.25\n",
      "GM 0.40555355282690636\n",
      "mean auc 0.3651315789473685\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aucs = list()\n",
    "y_probs_1, y_preds_1, y_true_1, conf_matrix = my_classifier_nn5(train_issues_0,train_issues_1,8,0.1,\n",
    "                                                                2*batch_size,v_batch,v_labels,t_batch,t_labels)\n",
    "\n",
    "aucs.append(compute_auc(y_true_1,y_probs_1)) \n",
    "compute_metrics(conf_matrix,aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c9903",
   "metadata": {},
   "source": [
    "#### DropOut Layer + Patience Remaining + Voting ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2d8e7",
   "metadata": {},
   "source": [
    "### Multiclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4bd68",
   "metadata": {},
   "source": [
    "Create a neural network for the moulticlassification problem.<br>\n",
    "The model will try to predict 3 classes Bug, Google play or Beta feedback, Prio-High.<br>\n",
    "To begin with every issue belongs only in one category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_classifier_nn(issues_embeddings,issues_labels,hidden_layer_dim,\n",
    "                        learning_rate,batch_size,epochs,v_batch,v_labels):\n",
    "    \n",
    "    # input data\n",
    "    X_train = tf.placeholder(tf.float64, shape=[None,np.shape(issues_embeddings)[1]])\n",
    "    \n",
    "    # input label\n",
    "    Y_train = tf.placeholder(tf.float64, shape=[None,3])\n",
    "    \n",
    "    # input-hidden layer variables\n",
    "    W1 = tf.Variable(tf.truncated_normal([np.shape(issues_embeddings)[1],hidden_layer_dim],\n",
    "                                         stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                         dtype=tf.float64),name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden_layer_dim],stddev = 1.0/ math.sqrt(hidden_layer_dim),\n",
    "                                      dtype=tf.float64),name = 'b1')\n",
    "    \n",
    "    # hidden-output layer variables\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_dim,3],\n",
    "                                         stddev = 1.0/ math.sqrt(3),\n",
    "                                         dtype=tf.float64),name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal([2],dtype=tf.float64),name = 'b2')\n",
    "    \n",
    "    # neural network's functions\n",
    "    hidden_layer   = tf.add(tf.matmul(X_train,W1),b1)\n",
    "    hidden_layer   = tf.nn.tanh(hidden_layer)\n",
    "     \n",
    "    output_layer   = tf.add(tf.matmul(hidden_layer,W2),b2)\n",
    "    output_layer_2 = tf.nn.softmax(output_layer)\n",
    "    \n",
    "    cost_func = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = Y_train,logits = output_layer))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_func)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # generate batch.\n",
    "            batch_x,batch_y = (issues_embeddings_0,issues_embeddings_1,batch_size)\n",
    "            \n",
    "            # train the model\n",
    "            _,loss = sess.run([optimizer,cost_func],feed_dict={X_train:batch_x,Y_train:batch_y})\n",
    "        \n",
    "        \n",
    "        # validation\n",
    "        y_probs     = sess.run(output_layer_2,feed_dict={X_train:v_batch,Y_train:v_labels})\n",
    "    \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
